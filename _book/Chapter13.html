<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£ â€“ æ·±åº¦å­¦ä¹ å®Œæ•´æ•™ç¨‹</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Chapter12.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5ea8f22911a6df30576a2a25a24cdd7a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter9.html">ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®è·µä¸åº”ç”¨</a></li><li class="breadcrumb-item"><a href="./Chapter13.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">æ·±åº¦å­¦ä¹ å®Œæ•´æ•™ç¨‹</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">ğŸ“‹ è¯¾ç¨‹æ•´ä½“æ¡†æ¶</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€ç¯‡</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">æœºå™¨å­¦ä¹ å®Œæ•´è¯¾ç¨‹</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">ç¬¬äºŒç« ï¼šå›å½’ (Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">ç¬¬ä¸‰ç« ï¼šåˆ†ç±»ä¸é€»è¾‘å›å½’ (Classification &amp; Logistic Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">ç¬¬å››ç« ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåŸºç¡€ (Deep Neural Networks)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬äºŒéƒ¨åˆ†ï¼šè¿›é˜¶ç¯‡</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">ç¬¬äº”ç« ï¼šä¼˜åŒ–ç®—æ³•ä¸è®­ç»ƒæŠ€å·§ (Optimization &amp; Training Tricks)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ç¬¬å…­ç« ï¼šå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">ç¬¬å…«ç« ï¼šAttention ä¸ Transformer</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®è·µä¸åº”ç”¨</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">ç¬¬ä¹ç« ï¼šè¿ç§»å­¦ä¹ ä¸å¾®è°ƒ (Transfer Learning &amp; Fine-tuning)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">ç¬¬åç« ï¼šå¼ºåŒ–å­¦ä¹  (Reinforcement Learning)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">ç¬¬åä¸€ç« ï¼šæ— ç›‘ç£å­¦ä¹  (Unsupervised Learning)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">ç¬¬åäºŒç« ï¼šå¯è§£é‡Šæ€§ä¸å¯¹æŠ—æ”»å‡»</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter13.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#ç« èŠ‚ç›®æ ‡" id="toc-ç« èŠ‚ç›®æ ‡" class="nav-link active" data-scroll-target="#ç« èŠ‚ç›®æ ‡"><span class="header-section-number">14.1</span> ğŸ“Œ ç« èŠ‚ç›®æ ‡</a></li>
  <li><a href="#ä»-gpt-åˆ°-chatgptå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›" id="toc-ä»-gpt-åˆ°-chatgptå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›" class="nav-link" data-scroll-target="#ä»-gpt-åˆ°-chatgptå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›"><span class="header-section-number">14.2</span> 13.1 ä» GPT åˆ° ChatGPTï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›</a>
  <ul class="collapse">
  <li><a href="#å…³é”®é‡Œç¨‹ç¢‘" id="toc-å…³é”®é‡Œç¨‹ç¢‘" class="nav-link" data-scroll-target="#å…³é”®é‡Œç¨‹ç¢‘"><span class="header-section-number">14.2.1</span> ğŸŒŸ å…³é”®é‡Œç¨‹ç¢‘</a></li>
  <li><a href="#æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°" id="toc-æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°" class="nav-link" data-scroll-target="#æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°"><span class="header-section-number">14.2.2</span> ğŸ“ æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°</a></li>
  </ul></li>
  <li><a href="#llm-çš„æ¶æ„åŸç†" id="toc-llm-çš„æ¶æ„åŸç†" class="nav-link" data-scroll-target="#llm-çš„æ¶æ„åŸç†"><span class="header-section-number">14.3</span> 13.2 LLM çš„æ¶æ„åŸç†</a>
  <ul class="collapse">
  <li><a href="#transformer-å›é¡¾" id="toc-transformer-å›é¡¾" class="nav-link" data-scroll-target="#transformer-å›é¡¾"><span class="header-section-number">14.3.1</span> ğŸ—ï¸ Transformer å›é¡¾</a></li>
  <li><a href="#gpt-æ¶æ„ç‰¹ç‚¹" id="toc-gpt-æ¶æ„ç‰¹ç‚¹" class="nav-link" data-scroll-target="#gpt-æ¶æ„ç‰¹ç‚¹"><span class="header-section-number">14.3.2</span> ğŸ”¹ GPT æ¶æ„ç‰¹ç‚¹</a></li>
  </ul></li>
  <li><a href="#é¢„è®­ç»ƒè‡ªç›‘ç£å­¦ä¹ " id="toc-é¢„è®­ç»ƒè‡ªç›‘ç£å­¦ä¹ " class="nav-link" data-scroll-target="#é¢„è®­ç»ƒè‡ªç›‘ç£å­¦ä¹ "><span class="header-section-number">14.4</span> 13.3 é¢„è®­ç»ƒï¼šè‡ªç›‘ç£å­¦ä¹ </a>
  <ul class="collapse">
  <li><a href="#é¢„è®­ç»ƒä»»åŠ¡" id="toc-é¢„è®­ç»ƒä»»åŠ¡" class="nav-link" data-scroll-target="#é¢„è®­ç»ƒä»»åŠ¡"><span class="header-section-number">14.4.1</span> ğŸ¯ é¢„è®­ç»ƒä»»åŠ¡</a></li>
  <li><a href="#é¢„è®­ç»ƒæµç¨‹" id="toc-é¢„è®­ç»ƒæµç¨‹" class="nav-link" data-scroll-target="#é¢„è®­ç»ƒæµç¨‹"><span class="header-section-number">14.4.2</span> ğŸ’» é¢„è®­ç»ƒæµç¨‹</a></li>
  </ul></li>
  <li><a href="#prompt-engineering" id="toc-prompt-engineering" class="nav-link" data-scroll-target="#prompt-engineering"><span class="header-section-number">14.5</span> 13.4 Prompt Engineering</a>
  <ul class="collapse">
  <li><a href="#ä»€ä¹ˆæ˜¯-prompt" id="toc-ä»€ä¹ˆæ˜¯-prompt" class="nav-link" data-scroll-target="#ä»€ä¹ˆæ˜¯-prompt"><span class="header-section-number">14.5.1</span> ğŸ¨ ä»€ä¹ˆæ˜¯ Promptï¼Ÿ</a></li>
  <li><a href="#prompt-è®¾è®¡åŸåˆ™" id="toc-prompt-è®¾è®¡åŸåˆ™" class="nav-link" data-scroll-target="#prompt-è®¾è®¡åŸåˆ™"><span class="header-section-number">14.5.2</span> ğŸ“Š Prompt è®¾è®¡åŸåˆ™</a></li>
  <li><a href="#prompt-æ¨¡æ¿ç¤ºä¾‹" id="toc-prompt-æ¨¡æ¿ç¤ºä¾‹" class="nav-link" data-scroll-target="#prompt-æ¨¡æ¿ç¤ºä¾‹"><span class="header-section-number">14.5.3</span> ğŸ’» Prompt æ¨¡æ¿ç¤ºä¾‹</a></li>
  <li><a href="#é«˜çº§-prompt-æŠ€å·§" id="toc-é«˜çº§-prompt-æŠ€å·§" class="nav-link" data-scroll-target="#é«˜çº§-prompt-æŠ€å·§"><span class="header-section-number">14.5.4</span> ğŸ”§ é«˜çº§ Prompt æŠ€å·§</a></li>
  </ul></li>
  <li><a href="#in-context-learning" id="toc-in-context-learning" class="nav-link" data-scroll-target="#in-context-learning"><span class="header-section-number">14.6</span> 13.5 In-Context Learning</a>
  <ul class="collapse">
  <li><a href="#æ ¸å¿ƒæ¦‚å¿µ" id="toc-æ ¸å¿ƒæ¦‚å¿µ" class="nav-link" data-scroll-target="#æ ¸å¿ƒæ¦‚å¿µ"><span class="header-section-number">14.6.1</span> ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ</a></li>
  <li><a href="#few-shot-learning-ç¤ºä¾‹" id="toc-few-shot-learning-ç¤ºä¾‹" class="nav-link" data-scroll-target="#few-shot-learning-ç¤ºä¾‹"><span class="header-section-number">14.6.2</span> ğŸ“Š Few-Shot Learning ç¤ºä¾‹</a></li>
  <li><a href="#ç¤ºä¾‹é€‰æ‹©ç­–ç•¥" id="toc-ç¤ºä¾‹é€‰æ‹©ç­–ç•¥" class="nav-link" data-scroll-target="#ç¤ºä¾‹é€‰æ‹©ç­–ç•¥"><span class="header-section-number">14.6.3</span> ğŸ”¹ ç¤ºä¾‹é€‰æ‹©ç­–ç•¥</a></li>
  </ul></li>
  <li><a href="#æŒ‡ä»¤å¾®è°ƒ-instruction-tuning" id="toc-æŒ‡ä»¤å¾®è°ƒ-instruction-tuning" class="nav-link" data-scroll-target="#æŒ‡ä»¤å¾®è°ƒ-instruction-tuning"><span class="header-section-number">14.7</span> 13.6 æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)</a>
  <ul class="collapse">
  <li><a href="#ä»-gpt-3-åˆ°-instructgpt" id="toc-ä»-gpt-3-åˆ°-instructgpt" class="nav-link" data-scroll-target="#ä»-gpt-3-åˆ°-instructgpt"><span class="header-section-number">14.7.1</span> ğŸ¯ ä» GPT-3 åˆ° InstructGPT</a></li>
  <li><a href="#ç›‘ç£å¾®è°ƒ-sft" id="toc-ç›‘ç£å¾®è°ƒ-sft" class="nav-link" data-scroll-target="#ç›‘ç£å¾®è°ƒ-sft"><span class="header-section-number">14.7.2</span> ğŸ’» ç›‘ç£å¾®è°ƒ (SFT)</a></li>
  <li><a href="#rlhf-reinforcement-learning-from-human-feedback" id="toc-rlhf-reinforcement-learning-from-human-feedback" class="nav-link" data-scroll-target="#rlhf-reinforcement-learning-from-human-feedback"><span class="header-section-number">14.7.3</span> ğŸ”¹ RLHF (Reinforcement Learning from Human Feedback)</a></li>
  </ul></li>
  <li><a href="#é«˜æ•ˆå¾®è°ƒlora-å’Œ-peft" id="toc-é«˜æ•ˆå¾®è°ƒlora-å’Œ-peft" class="nav-link" data-scroll-target="#é«˜æ•ˆå¾®è°ƒlora-å’Œ-peft"><span class="header-section-number">14.8</span> 13.7 é«˜æ•ˆå¾®è°ƒï¼šLoRA å’Œ PEFT</a>
  <ul class="collapse">
  <li><a href="#ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒ" id="toc-ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒ" class="nav-link" data-scroll-target="#ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒ"><span class="header-section-number">14.8.1</span> ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒï¼Ÿ</a></li>
  <li><a href="#lora-low-rank-adaptation" id="toc-lora-low-rank-adaptation" class="nav-link" data-scroll-target="#lora-low-rank-adaptation"><span class="header-section-number">14.8.2</span> ğŸ”¹ LoRA (Low-Rank Adaptation)</a></li>
  <li><a href="#å…¶ä»–-peft-æ–¹æ³•" id="toc-å…¶ä»–-peft-æ–¹æ³•" class="nav-link" data-scroll-target="#å…¶ä»–-peft-æ–¹æ³•"><span class="header-section-number">14.8.3</span> ğŸ”¹ å…¶ä»– PEFT æ–¹æ³•</a></li>
  </ul></li>
  <li><a href="#llm-åº”ç”¨èŒƒå¼" id="toc-llm-åº”ç”¨èŒƒå¼" class="nav-link" data-scroll-target="#llm-åº”ç”¨èŒƒå¼"><span class="header-section-number">14.9</span> 13.8 LLM åº”ç”¨èŒƒå¼</a>
  <ul class="collapse">
  <li><a href="#æ£€ç´¢å¢å¼ºç”Ÿæˆ-rag" id="toc-æ£€ç´¢å¢å¼ºç”Ÿæˆ-rag" class="nav-link" data-scroll-target="#æ£€ç´¢å¢å¼ºç”Ÿæˆ-rag"><span class="header-section-number">14.9.1</span> ğŸ”¹ æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)</a></li>
  <li><a href="#agent-ç³»ç»Ÿ" id="toc-agent-ç³»ç»Ÿ" class="nav-link" data-scroll-target="#agent-ç³»ç»Ÿ"><span class="header-section-number">14.9.2</span> ğŸ”¹ Agent ç³»ç»Ÿ</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter9.html">ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®è·µä¸åº”ç”¨</a></li><li class="breadcrumb-item"><a href="./Chapter13.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="ç« èŠ‚ç›®æ ‡" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="ç« èŠ‚ç›®æ ‡"><span class="header-section-number">14.1</span> ğŸ“Œ ç« èŠ‚ç›®æ ‡</h2>
<ul>
<li>ç†è§£å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ ¸å¿ƒåŸç†</li>
<li>æŒæ¡ Prompt Engineering æŠ€å·§</li>
<li>å­¦ä¹  In-Context Learning å’Œ Few-Shot Learning</li>
<li>äº†è§£ LLM çš„å¾®è°ƒæ–¹æ³•ï¼ˆLoRA, PEFTï¼‰</li>
<li>æ¢ç´¢ LLM çš„åº”ç”¨å’Œæœªæ¥æ–¹å‘</li>
</ul>
<hr>
</section>
<section id="ä»-gpt-åˆ°-chatgptå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="ä»-gpt-åˆ°-chatgptå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›"><span class="header-section-number">14.2</span> 13.1 ä» GPT åˆ° ChatGPTï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ¼”è¿›</h2>
<section id="å…³é”®é‡Œç¨‹ç¢‘" class="level3" data-number="14.2.1">
<h3 data-number="14.2.1" class="anchored" data-anchor-id="å…³é”®é‡Œç¨‹ç¢‘"><span class="header-section-number">14.2.1</span> ğŸŒŸ å…³é”®é‡Œç¨‹ç¢‘</h3>
<pre><code>2017: Transformer (Attention Is All You Need)
      â†“
2018: GPT-1 (117M å‚æ•°)
      BERT (340M å‚æ•°)
      â†“
2019: GPT-2 (1.5B å‚æ•°)
      T5, BART, XLNet
      â†“
2020: GPT-3 (175B å‚æ•°) ğŸ‘‘
      - Few-shot learning
      - In-context learning
      â†“
2022: ChatGPT (GPT-3.5 + RLHF)
      InstructGPT
      â†“
2023: GPT-4 (å¤šæ¨¡æ€)
      Claude, LLaMA, PaLM
      â†“
2024: Gemini, Claude 3
      å¼€æºæ¨¡å‹çˆ†å‘</code></pre>
<hr>
</section>
<section id="æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°" class="level3" data-number="14.2.2">
<h3 data-number="14.2.2" class="anchored" data-anchor-id="æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°"><span class="header-section-number">14.2.2</span> ğŸ“ æ ¸å¿ƒèƒ½åŠ›çš„æ¶Œç°</h3>
<p><strong>è§„æ¨¡å®šå¾‹ (Scaling Laws)</strong>ï¼š</p>
<pre><code>æ€§èƒ½ âˆ log(æ¨¡å‹å¤§å° Ã— æ•°æ®é‡ Ã— è®¡ç®—é‡)

æ¶Œç°èƒ½åŠ› (Emergent Abilities):
  - å°‘æ ·æœ¬å­¦ä¹ 
  - æŒ‡ä»¤éµå¾ª
  - æ€ç»´é“¾æ¨ç†
  - ä»£ç ç”Ÿæˆ
  - å¤šæ­¥æ¨ç†</code></pre>
<hr>
</section>
</section>
<section id="llm-çš„æ¶æ„åŸç†" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="llm-çš„æ¶æ„åŸç†"><span class="header-section-number">14.3</span> 13.2 LLM çš„æ¶æ„åŸç†</h2>
<section id="transformer-å›é¡¾" class="level3" data-number="14.3.1">
<h3 data-number="14.3.1" class="anchored" data-anchor-id="transformer-å›é¡¾"><span class="header-section-number">14.3.1</span> ğŸ—ï¸ Transformer å›é¡¾</h3>
<pre><code>è¾“å…¥ Token
    â†“
[Embedding + Positional Encoding]
    â†“
[Transformer Block] Ã—N
  - Multi-Head Attention
  - Feed-Forward Network
  - Layer Normalization
  - Residual Connection
    â†“
[Language Model Head]
    â†“
ä¸‹ä¸€ä¸ª Token çš„æ¦‚ç‡åˆ†å¸ƒ</code></pre>
</section>
<section id="gpt-æ¶æ„ç‰¹ç‚¹" class="level3" data-number="14.3.2">
<h3 data-number="14.3.2" class="anchored" data-anchor-id="gpt-æ¶æ„ç‰¹ç‚¹"><span class="header-section-number">14.3.2</span> ğŸ”¹ GPT æ¶æ„ç‰¹ç‚¹</h3>
<p><strong>åªç”¨ Decoderï¼ˆè‡ªå›å½’ï¼‰</strong>ï¼š</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPTBlock(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""GPT Transformer å—"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, n_heads, d_ff, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Causal Self-Attentionï¼ˆåªçœ‹å‰æ–‡ï¼‰</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> MultiHeadAttention(d_model, n_heads, dropout, causal<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Feed-Forward</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ff <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(d_model, d_ff),</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            nn.GELU(),</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            nn.Linear(d_ff, d_model),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Layer Norm</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln1 <span class="op">=</span> nn.LayerNorm(d_model)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln2 <span class="op">=</span> nn.LayerNorm(d_model)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pre-LN æ¶æ„</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.attn(<span class="va">self</span>.ln1(x), mask)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.ff(<span class="va">self</span>.ln2(x))</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPTModel(nn.Module):</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ç®€åŒ–çš„ GPT æ¨¡å‹"""</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, d_model<span class="op">=</span><span class="dv">768</span>, n_heads<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>                 n_layers<span class="op">=</span><span class="dv">12</span>, d_ff<span class="op">=</span><span class="dv">3072</span>, max_len<span class="op">=</span><span class="dv">1024</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Token Embedding</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.token_emb <span class="op">=</span> nn.Embedding(vocab_size, d_model)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional Embeddingï¼ˆå¯å­¦ä¹ ï¼‰</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pos_emb <span class="op">=</span> nn.Embedding(max_len, d_model)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer Blocks</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blocks <span class="op">=</span> nn.ModuleList([</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>            GPTBlock(d_model, n_heads, d_ff, dropout)</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final Layer Norm</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_f <span class="op">=</span> nn.LayerNorm(d_model)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Language Model Head</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lm_head <span class="op">=</span> nn.Linear(d_model, vocab_size, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æƒé‡å…±äº«ï¼ˆembedding å’Œ lm_headï¼‰</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lm_head.weight <span class="op">=</span> <span class="va">self</span>.token_emb.weight</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_ids, labels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°:</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a><span class="co">            input_ids: (batch, seq_len)</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="co">            labels: (batch, seq_len) å¯é€‰ï¼Œç”¨äºè®­ç»ƒ</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>        batch_size, seq_len <span class="op">=</span> input_ids.shape</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>        token_embeddings <span class="op">=</span> <span class="va">self</span>.token_emb(input_ids)  <span class="co"># (B, T, D)</span></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional Embedding</span></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> torch.arange(<span class="dv">0</span>, seq_len, device<span class="op">=</span>input_ids.device)</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        position_embeddings <span class="op">=</span> <span class="va">self</span>.pos_emb(positions)  <span class="co"># (T, D)</span></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout(token_embeddings <span class="op">+</span> position_embeddings)</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Causal Maskï¼ˆä¸‹ä¸‰è§’çŸ©é˜µï¼‰</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> torch.tril(torch.ones(seq_len, seq_len, device<span class="op">=</span>input_ids.device))</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> mask.view(<span class="dv">1</span>, <span class="dv">1</span>, seq_len, seq_len)</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transformer Blocks</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> block <span class="kw">in</span> <span class="va">self</span>.blocks:</span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> block(x, mask)</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.ln_f(x)</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Logits</span></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.lm_head(x)  <span class="co"># (B, T, vocab_size)</span></span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è®¡ç®—æŸå¤±ï¼ˆå¦‚æœæä¾›äº†æ ‡ç­¾ï¼‰</span></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> labels <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ç§»ä½ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ª token</span></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>            shift_logits <span class="op">=</span> logits[:, :<span class="op">-</span><span class="dv">1</span>, :].contiguous()</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>            shift_labels <span class="op">=</span> labels[:, <span class="dv">1</span>:].contiguous()</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.cross_entropy(</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>                shift_logits.view(<span class="op">-</span><span class="dv">1</span>, shift_logits.size(<span class="op">-</span><span class="dv">1</span>)),</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>                shift_labels.view(<span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>                ignore_index<span class="op">=-</span><span class="dv">100</span></span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits, loss</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(<span class="va">self</span>, input_ids, max_new_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>                temperature<span class="op">=</span><span class="fl">1.0</span>, top_k<span class="op">=</span><span class="va">None</span>, top_p<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a><span class="co">        è‡ªå›å½’ç”Ÿæˆ</span></span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°:</span></span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a><span class="co">            input_ids: (batch, seq_len) è¾“å…¥åºåˆ—</span></span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a><span class="co">            max_new_tokens: ç”Ÿæˆçš„æœ€å¤§ token æ•°</span></span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a><span class="co">            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰</span></span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a><span class="co">            top_k: Top-K é‡‡æ ·</span></span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a><span class="co">            top_p: Nucleus (Top-P) é‡‡æ ·</span></span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_new_tokens):</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æˆªæ–­åˆ°æœ€å¤§é•¿åº¦ï¼ˆé¿å…è¶…è¿‡ä½ç½®ç¼–ç ï¼‰</span></span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>            input_ids_cond <span class="op">=</span> input_ids <span class="cf">if</span> input_ids.size(<span class="dv">1</span>) <span class="op">&lt;=</span> <span class="dv">1024</span> <span class="cf">else</span> input_ids[:, <span class="op">-</span><span class="dv">1024</span>:]</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>            logits, _ <span class="op">=</span> <span class="va">self</span>.forward(input_ids_cond)</span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è·å–æœ€åä¸€ä¸ªä½ç½®çš„ logits</span></span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :] <span class="op">/</span> temperature</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Top-K é‡‡æ ·</span></span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> top_k <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>                v, _ <span class="op">=</span> torch.topk(logits, <span class="bu">min</span>(top_k, logits.size(<span class="op">-</span><span class="dv">1</span>)))</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>                logits[logits <span class="op">&lt;</span> v[:, [<span class="op">-</span><span class="dv">1</span>]]] <span class="op">=</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">'Inf'</span>)</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Top-P (Nucleus) é‡‡æ ·</span></span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> top_p <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>                sorted_logits, sorted_indices <span class="op">=</span> torch.sort(logits, descending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>                cumulative_probs <span class="op">=</span> torch.cumsum(F.softmax(sorted_logits, dim<span class="op">=-</span><span class="dv">1</span>), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>                <span class="co"># ç§»é™¤ç´¯ç§¯æ¦‚ç‡è¶…è¿‡ top_p çš„ tokens</span></span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>                sorted_indices_to_remove <span class="op">=</span> cumulative_probs <span class="op">&gt;</span> top_p</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>                sorted_indices_to_remove[:, <span class="dv">1</span>:] <span class="op">=</span> sorted_indices_to_remove[:, :<span class="op">-</span><span class="dv">1</span>].clone()</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>                sorted_indices_to_remove[:, <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(logits.size(<span class="dv">0</span>)):</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>                    indices_to_remove <span class="op">=</span> sorted_indices[i, sorted_indices_to_remove[i]]</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>                    logits[i, indices_to_remove] <span class="op">=</span> <span class="op">-</span><span class="bu">float</span>(<span class="st">'Inf'</span>)</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>            <span class="co"># é‡‡æ ·</span></span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>            next_token <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ‹¼æ¥</span></span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> torch.cat([input_ids, next_token], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> input_ids</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="é¢„è®­ç»ƒè‡ªç›‘ç£å­¦ä¹ " class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="é¢„è®­ç»ƒè‡ªç›‘ç£å­¦ä¹ "><span class="header-section-number">14.4</span> 13.3 é¢„è®­ç»ƒï¼šè‡ªç›‘ç£å­¦ä¹ </h2>
<section id="é¢„è®­ç»ƒä»»åŠ¡" class="level3" data-number="14.4.1">
<h3 data-number="14.4.1" class="anchored" data-anchor-id="é¢„è®­ç»ƒä»»åŠ¡"><span class="header-section-number">14.4.1</span> ğŸ¯ é¢„è®­ç»ƒä»»åŠ¡</h3>
<pre><code>è¯­è¨€æ¨¡å‹ç›®æ ‡ï¼š
  ç»™å®šä¸Šæ–‡ xâ‚, xâ‚‚, ..., x_{t-1}ï¼Œé¢„æµ‹ x_t

  P(x_t | xâ‚, ..., x_{t-1})

æŸå¤±å‡½æ•°ï¼š
  L = -âˆ‘_t log P(x_t | xâ‚, ..., x_{t-1})</code></pre>
</section>
<section id="é¢„è®­ç»ƒæµç¨‹" class="level3" data-number="14.4.2">
<h3 data-number="14.4.2" class="anchored" data-anchor-id="é¢„è®­ç»ƒæµç¨‹"><span class="header-section-number">14.4.2</span> ğŸ’» é¢„è®­ç»ƒæµç¨‹</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_gpt(model, dataloader, num_epochs<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""é¢„è®­ç»ƒ GPT"""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">3e-4</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>                                  betas<span class="op">=</span>(<span class="fl">0.9</span>, <span class="fl">0.95</span>), weight_decay<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># å­¦ä¹ ç‡è°ƒåº¦ï¼ˆwarmup + cosine decayï¼‰</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_lr(step, warmup_steps<span class="op">=</span><span class="dv">2000</span>, max_steps<span class="op">=</span><span class="dv">100000</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> step <span class="op">&lt;</span> warmup_steps:</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> step <span class="op">/</span> warmup_steps</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> np.cos(np.pi <span class="op">*</span> (step <span class="op">-</span> warmup_steps) <span class="op">/</span> (max_steps <span class="op">-</span> warmup_steps)))</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> torch.optim.lr_scheduler.LambdaLR(</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        optimizer, lr_lambda<span class="op">=</span><span class="kw">lambda</span> step: get_lr(step)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    step <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> batch[<span class="st">'input_ids'</span>].to(device)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> input_ids.clone()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>            logits, loss <span class="op">=</span> model(input_ids, labels)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># åå‘ä¼ æ’­</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ¢¯åº¦è£å‰ª</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>            scheduler.step()</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>            step <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> step <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f'Step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">, '</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>                      <span class="ss">f'LR = </span><span class="sc">{</span>scheduler<span class="sc">.</span>get_last_lr()[<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">'</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: Avg Loss = </span><span class="sc">{</span>avg_loss<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="prompt-engineering" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="prompt-engineering"><span class="header-section-number">14.5</span> 13.4 Prompt Engineering</h2>
<section id="ä»€ä¹ˆæ˜¯-prompt" class="level3" data-number="14.5.1">
<h3 data-number="14.5.1" class="anchored" data-anchor-id="ä»€ä¹ˆæ˜¯-prompt"><span class="header-section-number">14.5.1</span> ğŸ¨ ä»€ä¹ˆæ˜¯ Promptï¼Ÿ</h3>
<pre><code>Prompt = ç»™æ¨¡å‹çš„æŒ‡ä»¤/ç¤ºä¾‹

ä¾‹ï¼š
  è¾“å…¥ï¼š"å°†ä¸‹é¢çš„è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š\nHello, world!"
  æ¨¡å‹ï¼šæ ¹æ® prompt ç†è§£ä»»åŠ¡ï¼Œç”Ÿæˆç¿»è¯‘</code></pre>
</section>
<section id="prompt-è®¾è®¡åŸåˆ™" class="level3" data-number="14.5.2">
<h3 data-number="14.5.2" class="anchored" data-anchor-id="prompt-è®¾è®¡åŸåˆ™"><span class="header-section-number">14.5.2</span> ğŸ“Š Prompt è®¾è®¡åŸåˆ™</h3>
<section id="æ¸…æ™°æ˜ç¡®" class="level4" data-number="14.5.2.1">
<h4 data-number="14.5.2.1" class="anchored" data-anchor-id="æ¸…æ™°æ˜ç¡®"><span class="header-section-number">14.5.2.1</span> <strong>1. æ¸…æ™°æ˜ç¡®</strong></h4>
<pre><code>âŒ å·®çš„ Prompt:
  "å…³äº AI"

âœ… å¥½çš„ Prompt:
  "è¯·ç”¨ 200 å­—ä»‹ç»äººå·¥æ™ºèƒ½çš„å®šä¹‰ã€å‘å±•å†ç¨‹å’Œä¸»è¦åº”ç”¨é¢†åŸŸã€‚"</code></pre>
</section>
<section id="æä¾›ä¸Šä¸‹æ–‡" class="level4" data-number="14.5.2.2">
<h4 data-number="14.5.2.2" class="anchored" data-anchor-id="æä¾›ä¸Šä¸‹æ–‡"><span class="header-section-number">14.5.2.2</span> <strong>2. æä¾›ä¸Šä¸‹æ–‡</strong></h4>
<pre><code>âŒ æ— ä¸Šä¸‹æ–‡:
  "è¿™ä¸ªæ€ä¹ˆæ ·ï¼Ÿ"

âœ… æœ‰ä¸Šä¸‹æ–‡:
  "æˆ‘æ­£åœ¨å†™ä¸€ç¯‡å…³äºæ°”å€™å˜åŒ–çš„æ–‡ç« ã€‚ä»¥ä¸‹æ˜¯è‰ç¨¿çš„ç¬¬ä¸€æ®µï¼š
  [æ®µè½å†…å®¹]
  è¯·è¯„ä»·è¿™æ®µå†…å®¹çš„é€»è¾‘æ€§å’Œè¯´æœåŠ›ã€‚"</code></pre>
</section>
<section id="ä½¿ç”¨ç¤ºä¾‹few-shot" class="level4" data-number="14.5.2.3">
<h4 data-number="14.5.2.3" class="anchored" data-anchor-id="ä½¿ç”¨ç¤ºä¾‹few-shot"><span class="header-section-number">14.5.2.3</span> <strong>3. ä½¿ç”¨ç¤ºä¾‹ï¼ˆFew-shotï¼‰</strong></h4>
<pre><code>Zero-shotï¼ˆæ— ç¤ºä¾‹ï¼‰:
  "æƒ…æ„Ÿåˆ†ç±»ï¼šè¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹"

Few-shotï¼ˆæœ‰ç¤ºä¾‹ï¼‰:
  """
  æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ï¼š

  ç¤ºä¾‹ï¼š
  æ–‡æœ¬: "è¿™å®¶é¤å…å¤ªå·®äº†" â†’ è´Ÿé¢
  æ–‡æœ¬: "æœåŠ¡æ€åº¦å¾ˆå¥½" â†’ æ­£é¢
  æ–‡æœ¬: "è¿˜è¡Œå§" â†’ ä¸­æ€§

  ç°åœ¨åˆ†ç±»ï¼š
  æ–‡æœ¬: "è¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹" â†’
  """</code></pre>
</section>
<section id="æ€ç»´é“¾chain-of-thought" class="level4" data-number="14.5.2.4">
<h4 data-number="14.5.2.4" class="anchored" data-anchor-id="æ€ç»´é“¾chain-of-thought"><span class="header-section-number">14.5.2.4</span> <strong>4. æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰</strong></h4>
<pre><code>æ™®é€š Prompt:
  "Roger æœ‰ 5 ä¸ªç½‘çƒã€‚ä»–åˆä¹°äº† 2 ç½ç½‘çƒï¼Œæ¯ç½ 3 ä¸ªçƒã€‚
   ä»–ç°åœ¨æœ‰å¤šå°‘ä¸ªç½‘çƒï¼Ÿ"

CoT Prompt:
  "Roger æœ‰ 5 ä¸ªç½‘çƒã€‚ä»–åˆä¹°äº† 2 ç½ç½‘çƒï¼Œæ¯ç½ 3 ä¸ªçƒã€‚
   ä»–ç°åœ¨æœ‰å¤šå°‘ä¸ªç½‘çƒï¼Ÿ

   è®©æˆ‘ä»¬ä¸€æ­¥æ­¥æ€è€ƒï¼š
   1. Roger æœ€åˆæœ‰ 5 ä¸ªç½‘çƒ
   2. ä»–ä¹°äº† 2 ç½ï¼Œæ¯ç½ 3 ä¸ªï¼Œæ‰€ä»¥ä¹°äº† 2Ã—3=6 ä¸ª
   3. æ€»å…±ï¼š5+6=11 ä¸ª

   ç­”æ¡ˆï¼š11 ä¸ªç½‘çƒ"</code></pre>
<hr>
</section>
</section>
<section id="prompt-æ¨¡æ¿ç¤ºä¾‹" class="level3" data-number="14.5.3">
<h3 data-number="14.5.3" class="anchored" data-anchor-id="prompt-æ¨¡æ¿ç¤ºä¾‹"><span class="header-section-number">14.5.3</span> ğŸ’» Prompt æ¨¡æ¿ç¤ºä¾‹</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PromptTemplate:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Prompt æ¨¡æ¿ç®¡ç†"""</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.templates <span class="op">=</span> {</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">'translation'</span>: <span class="st">"""</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="st">Translate the following </span><span class="sc">{source_lang}</span><span class="st"> text to </span><span class="sc">{target_lang}</span><span class="st">:</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="st">Text: </span><span class="sc">{text}</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="st">Translation:"""</span>,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">'summarization'</span>: <span class="st">"""</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="st">Summarize the following text in </span><span class="sc">{num_sentences}</span><span class="st"> sentences:</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="sc">{text}</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="st">Summary:"""</span>,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'classification'</span>: <span class="st">"""</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="st">Classify the sentiment of the following text as Positive, Negative, or Neutral.</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="st">Examples:</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="sc">{examples}</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="st">Text: </span><span class="sc">{text}</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="st">Sentiment:"""</span>,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">'qa'</span>: <span class="st">"""</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="st">Answer the following question based on the context.</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="st">Context: </span><span class="sc">{context}</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="st">Answer:"""</span>,</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">'cot_reasoning'</span>: <span class="st">"""</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="st">Question: </span><span class="sc">{question}</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="st">Let's think step by step:</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>,</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">format</span>(<span class="va">self</span>, template_name, <span class="op">**</span>kwargs):</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""æ ¼å¼åŒ–æ¨¡æ¿"""</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>        template <span class="op">=</span> <span class="va">self</span>.templates[template_name]</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> template.<span class="bu">format</span>(<span class="op">**</span>kwargs)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== ä½¿ç”¨ç¤ºä¾‹ ====================</span></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>prompt_template <span class="op">=</span> PromptTemplate()</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a><span class="co"># ç¿»è¯‘</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>translation_prompt <span class="op">=</span> prompt_template.<span class="bu">format</span>(</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'translation'</span>,</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>    source_lang<span class="op">=</span><span class="st">'English'</span>,</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>    target_lang<span class="op">=</span><span class="st">'Chinese'</span>,</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>    text<span class="op">=</span><span class="st">'Hello, how are you?'</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Few-shot åˆ†ç±»</span></span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="st">Text: "This movie is amazing!" â†’ Positive</span></span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a><span class="st">Text: "Waste of time." â†’ Negative</span></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a><span class="st">Text: "It's okay." â†’ Neutral"""</span></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>classification_prompt <span class="op">=</span> prompt_template.<span class="bu">format</span>(</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>    <span class="st">'classification'</span>,</span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>    examples<span class="op">=</span>examples,</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>    text<span class="op">=</span><span class="st">'I love this product!'</span></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_prompt)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="é«˜çº§-prompt-æŠ€å·§" class="level3" data-number="14.5.4">
<h3 data-number="14.5.4" class="anchored" data-anchor-id="é«˜çº§-prompt-æŠ€å·§"><span class="header-section-number">14.5.4</span> ğŸ”§ é«˜çº§ Prompt æŠ€å·§</h3>
<section id="è§’è‰²æ‰®æ¼”-role-playing" class="level4" data-number="14.5.4.1">
<h4 data-number="14.5.4.1" class="anchored" data-anchor-id="è§’è‰²æ‰®æ¼”-role-playing"><span class="header-section-number">14.5.4.1</span> <strong>1. è§’è‰²æ‰®æ¼” (Role-Playing)</strong></h4>
<pre><code>"ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python ç¨‹åºå‘˜ã€‚è¯·å¸®æˆ‘ä¼˜åŒ–ä»¥ä¸‹ä»£ç ï¼š
[ä»£ç ]"</code></pre>
</section>
<section id="çº¦æŸæ¡ä»¶" class="level4" data-number="14.5.4.2">
<h4 data-number="14.5.4.2" class="anchored" data-anchor-id="çº¦æŸæ¡ä»¶"><span class="header-section-number">14.5.4.2</span> <strong>2. çº¦æŸæ¡ä»¶</strong></h4>
<pre><code>"ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€ï¼ˆé€‚åˆ 10 å²å„¿ç«¥ç†è§£ï¼‰è§£é‡Šä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œã€‚
è¦æ±‚ï¼š
- ä¸è¶…è¿‡ 3 æ®µ
- ä½¿ç”¨æ—¥å¸¸ç”Ÿæ´»çš„æ¯”å–»
- é¿å…ä¸“ä¸šæœ¯è¯­"</code></pre>
</section>
<section id="è¾“å‡ºæ ¼å¼" class="level4" data-number="14.5.4.3">
<h4 data-number="14.5.4.3" class="anchored" data-anchor-id="è¾“å‡ºæ ¼å¼"><span class="header-section-number">14.5.4.3</span> <strong>3. è¾“å‡ºæ ¼å¼</strong></h4>
<pre><code>"åˆ†æä»¥ä¸‹äº§å“è¯„è®ºï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
{
  "sentiment": "positive/negative/neutral",
  "key_points": ["point1", "point2"],
  "rating": 1-5
}

è¯„è®ºï¼š[è¯„è®ºå†…å®¹]"</code></pre>
</section>
<section id="è‡ªæˆ‘ä¸€è‡´æ€§-self-consistency" class="level4" data-number="14.5.4.4">
<h4 data-number="14.5.4.4" class="anchored" data-anchor-id="è‡ªæˆ‘ä¸€è‡´æ€§-self-consistency"><span class="header-section-number">14.5.4.4</span> <strong>4. è‡ªæˆ‘ä¸€è‡´æ€§ (Self-Consistency)</strong></h4>
<pre><code>å¤šæ¬¡ç”Ÿæˆç­”æ¡ˆï¼Œé€‰æ‹©æœ€ä¸€è‡´çš„ç»“æœ</code></pre>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> self_consistency_generate(model, tokenizer, prompt, n<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""è‡ªæˆ‘ä¸€è‡´æ€§ç”Ÿæˆ"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    answers <span class="op">=</span> []</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç”Ÿæˆç­”æ¡ˆï¼ˆå¸¦éšæœºæ€§ï¼‰</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">'pt'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model.generate(</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>            inputs[<span class="st">'input_ids'</span>],</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>            max_new_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>            do_sample<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        answer <span class="op">=</span> tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        answers.append(answer)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># é€‰æ‹©æœ€å¸¸è§çš„ç­”æ¡ˆ</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    most_common <span class="op">=</span> Counter(answers).most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> most_common, answers</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
</section>
<section id="in-context-learning" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="in-context-learning"><span class="header-section-number">14.6</span> 13.5 In-Context Learning</h2>
<section id="æ ¸å¿ƒæ¦‚å¿µ" class="level3" data-number="14.6.1">
<h3 data-number="14.6.1" class="anchored" data-anchor-id="æ ¸å¿ƒæ¦‚å¿µ"><span class="header-section-number">14.6.1</span> ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ</h3>
<pre><code>In-Context Learning:
  åœ¨è¾“å…¥ä¸­æä¾›ç¤ºä¾‹ï¼Œæ— éœ€æ›´æ–°å‚æ•°

å…³é”®ç‰¹æ€§ï¼š
  âœ“ æ— éœ€æ¢¯åº¦æ›´æ–°
  âœ“ å³æ—¶é€‚åº”æ–°ä»»åŠ¡
  âœ“ çµæ´»æ€§é«˜</code></pre>
</section>
<section id="few-shot-learning-ç¤ºä¾‹" class="level3" data-number="14.6.2">
<h3 data-number="14.6.2" class="anchored" data-anchor-id="few-shot-learning-ç¤ºä¾‹"><span class="header-section-number">14.6.2</span> ğŸ“Š Few-Shot Learning ç¤ºä¾‹</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FewShotLearner:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Few-Shot Learning åŒ…è£…å™¨"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, tokenizer):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_few_shot_prompt(<span class="va">self</span>, task, examples, query):</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">        åˆ›å»º Few-Shot Prompt</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°:</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">            task: ä»»åŠ¡æè¿°</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">            examples: [(input, output), ...]</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">            query: æŸ¥è¯¢è¾“å…¥</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>task<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ·»åŠ ç¤ºä¾‹</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, (inp, out) <span class="kw">in</span> <span class="bu">enumerate</span>(examples, <span class="dv">1</span>):</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>            prompt <span class="op">+=</span> <span class="ss">f"Example </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>            prompt <span class="op">+=</span> <span class="ss">f"Input: </span><span class="sc">{</span>inp<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>            prompt <span class="op">+=</span> <span class="ss">f"Output: </span><span class="sc">{</span>out<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ·»åŠ æŸ¥è¯¢</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">+=</span> <span class="ss">f"Now solve:</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">+=</span> <span class="ss">f"Input: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">+=</span> <span class="ss">f"Output:"</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> prompt</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, task, examples, query, max_tokens<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Few-Shot é¢„æµ‹"""</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆ›å»º prompt</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="va">self</span>.create_few_shot_prompt(task, examples, query)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç”Ÿæˆ</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">self</span>.tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">'pt'</span>)</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> <span class="va">self</span>.model.generate(</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>            inputs[<span class="st">'input_ids'</span>],</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>            max_new_tokens<span class="op">=</span>max_tokens,</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>            top_p<span class="op">=</span><span class="fl">0.9</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è§£ç </span></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> <span class="va">self</span>.tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æå–è¾“å‡ºéƒ¨åˆ†</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> result.split(<span class="st">"Output:"</span>)[<span class="op">-</span><span class="dv">1</span>].strip()</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== ä½¿ç”¨ç¤ºä¾‹ ====================</span></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a><span class="co"># æƒ…æ„Ÿåˆ†ç±» Few-Shot</span></span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>task <span class="op">=</span> <span class="st">"Classify the sentiment of the text as Positive or Negative."</span></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> [</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"I love this product!"</span>, <span class="st">"Positive"</span>),</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Terrible experience."</span>, <span class="st">"Negative"</span>),</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Best purchase ever!"</span>, <span class="st">"Positive"</span>),</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Complete waste of money."</span>, <span class="st">"Negative"</span>),</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"This exceeded my expectations."</span></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>learner <span class="op">=</span> FewShotLearner(model, tokenizer)</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> learner.predict(task, examples, query)</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Query: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="ç¤ºä¾‹é€‰æ‹©ç­–ç•¥" class="level3" data-number="14.6.3">
<h3 data-number="14.6.3" class="anchored" data-anchor-id="ç¤ºä¾‹é€‰æ‹©ç­–ç•¥"><span class="header-section-number">14.6.3</span> ğŸ”¹ ç¤ºä¾‹é€‰æ‹©ç­–ç•¥</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> select_diverse_examples(example_pool, query, n<span class="op">=</span><span class="dv">5</span>, method<span class="op">=</span><span class="st">'semantic'</span>):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">    é€‰æ‹©å¤šæ ·åŒ–çš„ç¤ºä¾‹</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">    æ–¹æ³•:</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">        - random: éšæœºé€‰æ‹©</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">        - semantic: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - diverse: æœ€å¤§åŒ–å¤šæ ·æ€§</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> method <span class="op">==</span> <span class="st">'random'</span>:</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> random.sample(example_pool, n)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'semantic'</span>:</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åŠ è½½å¥å­ç¼–ç å™¨</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        encoder <span class="op">=</span> SentenceTransformer(<span class="st">'all-MiniLM-L6-v2'</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç¼–ç æŸ¥è¯¢å’Œç¤ºä¾‹</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        query_emb <span class="op">=</span> encoder.encode([query])[<span class="dv">0</span>]</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        example_embs <span class="op">=</span> encoder.encode([ex[<span class="dv">0</span>] <span class="cf">for</span> ex <span class="kw">in</span> example_pool])</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è®¡ç®—ç›¸ä¼¼åº¦</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> cosine_similarity([query_emb], example_embs)[<span class="dv">0</span>]</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é€‰æ‹©æœ€ç›¸ä¼¼çš„</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>        top_indices <span class="op">=</span> np.argsort(similarities)[<span class="op">-</span>n:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [example_pool[i] <span class="cf">for</span> i <span class="kw">in</span> top_indices]</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'diverse'</span>:</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># k-means èšç±»é€‰æ‹©å¤šæ ·åŒ–ç¤ºä¾‹</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        encoder <span class="op">=</span> SentenceTransformer(<span class="st">'all-MiniLM-L6-v2'</span>)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        example_embs <span class="op">=</span> encoder.encode([ex[<span class="dv">0</span>] <span class="cf">for</span> ex <span class="kw">in</span> example_pool])</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># èšç±»</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        kmeans.fit(example_embs)</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä»æ¯ä¸ªç°‡é€‰æ‹©æœ€æ¥è¿‘ä¸­å¿ƒçš„ç¤ºä¾‹</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>        selected <span class="op">=</span> []</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>            cluster_indices <span class="op">=</span> np.where(kmeans.labels_ <span class="op">==</span> i)[<span class="dv">0</span>]</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>            center <span class="op">=</span> kmeans.cluster_centers_[i]</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ‰¾æœ€æ¥è¿‘ä¸­å¿ƒçš„</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>            distances <span class="op">=</span> np.linalg.norm(example_embs[cluster_indices] <span class="op">-</span> center, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>            closest_idx <span class="op">=</span> cluster_indices[np.argmin(distances)]</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>            selected.append(example_pool[closest_idx])</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> selected</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="æŒ‡ä»¤å¾®è°ƒ-instruction-tuning" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="æŒ‡ä»¤å¾®è°ƒ-instruction-tuning"><span class="header-section-number">14.7</span> 13.6 æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)</h2>
<section id="ä»-gpt-3-åˆ°-instructgpt" class="level3" data-number="14.7.1">
<h3 data-number="14.7.1" class="anchored" data-anchor-id="ä»-gpt-3-åˆ°-instructgpt"><span class="header-section-number">14.7.1</span> ğŸ¯ ä» GPT-3 åˆ° InstructGPT</h3>
<pre><code>é—®é¢˜ï¼š
  GPT-3 è™½ç„¶å¼ºå¤§ï¼Œä½†ä¸æ€»æ˜¯éµå¾ªç”¨æˆ·æŒ‡ä»¤

è§£å†³ï¼š
  Instruction Tuning + RLHF

æµç¨‹ï¼š
  1. æ”¶é›†æŒ‡ä»¤-å“åº”æ•°æ®
  2. ç›‘ç£å¾®è°ƒ (SFT)
  3. æ”¶é›†äººç±»åå¥½æ•°æ®
  4. è®­ç»ƒå¥–åŠ±æ¨¡å‹ (RM)
  5. å¼ºåŒ–å­¦ä¹ å¾®è°ƒ (PPO)</code></pre>
</section>
<section id="ç›‘ç£å¾®è°ƒ-sft" class="level3" data-number="14.7.2">
<h3 data-number="14.7.2" class="anchored" data-anchor-id="ç›‘ç£å¾®è°ƒ-sft"><span class="header-section-number">14.7.2</span> ğŸ’» ç›‘ç£å¾®è°ƒ (SFT)</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> instruction_tuning(model, instruction_dataset, num_epochs<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">    æŒ‡ä»¤å¾®è°ƒ</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">    æ•°æ®æ ¼å¼:</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">    {</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">        "instruction": "å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡",</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">        "input": "Hello, world!",</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">        "output": "ä½ å¥½ï¼Œä¸–ç•Œï¼"</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">    }</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> instruction_dataset:</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ ¼å¼åŒ–ä¸º prompt</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>            prompts <span class="op">=</span> []</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> item <span class="kw">in</span> batch:</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>                prompt <span class="op">=</span> <span class="ss">f"### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>item[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> item.get(<span class="st">'input'</span>):</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>                    prompt <span class="op">+=</span> <span class="ss">f"### Input:</span><span class="ch">\n</span><span class="sc">{</span>item[<span class="st">'input'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>                prompt <span class="op">+=</span> <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>item[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>                prompts.append(prompt)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tokenize</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> tokenizer(prompts, return_tensors<span class="op">=</span><span class="st">'pt'</span>,</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>                             padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {k: v.to(device) <span class="cf">for</span> k, v <span class="kw">in</span> inputs.items()}</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(<span class="op">**</span>inputs, labels<span class="op">=</span>inputs[<span class="st">'input_ids'</span>])</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> outputs.loss</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># åå‘ä¼ æ’­</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>total_loss<span class="op">/</span><span class="bu">len</span>(instruction_dataset)<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="rlhf-reinforcement-learning-from-human-feedback" class="level3" data-number="14.7.3">
<h3 data-number="14.7.3" class="anchored" data-anchor-id="rlhf-reinforcement-learning-from-human-feedback"><span class="header-section-number">14.7.3</span> ğŸ”¹ RLHF (Reinforcement Learning from Human Feedback)</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RewardModel(nn.Module):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""å¥–åŠ±æ¨¡å‹"""</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, base_model):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_model <span class="op">=</span> base_model</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¥–åŠ±å¤´</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reward_head <span class="op">=</span> nn.Linear(base_model.config.hidden_size, <span class="dv">1</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_ids, attention_mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è·å–æœ€åä¸€ä¸ª token çš„éšè—çŠ¶æ€</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> <span class="va">self</span>.base_model(input_ids, attention_mask<span class="op">=</span>attention_mask)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        last_hidden <span class="op">=</span> outputs.last_hidden_state[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é¢„æµ‹å¥–åŠ±</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        reward <span class="op">=</span> <span class="va">self</span>.reward_head(last_hidden)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> reward</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_reward_model(model, comparison_dataset):</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">    è®­ç»ƒå¥–åŠ±æ¨¡å‹</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co">    æ•°æ®æ ¼å¼ï¼š(prompt, response_A, response_B, preference)</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co">    preference: 0 è¡¨ç¤º A æ›´å¥½ï¼Œ1 è¡¨ç¤º B æ›´å¥½</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> comparison_dataset:</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>            prompts, responses_A, responses_B, preferences <span class="op">=</span> batch</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è®¡ç®—å¥–åŠ±</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>            rewards_A <span class="op">=</span> model(responses_A)</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>            rewards_B <span class="op">=</span> model(responses_B)</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æŸå¤±ï¼šåå¥½çš„å“åº”åº”è¯¥æœ‰æ›´é«˜å¥–åŠ±</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="op">-</span>torch.log(torch.sigmoid(</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>                (rewards_A <span class="op">-</span> rewards_B) <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> preferences <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>            )).mean()</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rlhf_training(policy_model, reward_model, prompts):</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="co">    ä½¿ç”¨ PPO è¿›è¡Œ RLHF</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a><span class="co">    ç®€åŒ–ç‰ˆæœ¬ï¼ˆå®é™…å®ç°æ›´å¤æ‚ï¼‰</span></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(policy_model.parameters(), lr<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> prompt <span class="kw">in</span> prompts:</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ç”Ÿæˆå“åº”</span></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>                response <span class="op">=</span> policy_model.generate(prompt)</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è®¡ç®—å¥–åŠ±</span></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>            reward <span class="op">=</span> reward_model(response)</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PPO æ›´æ–°ï¼ˆç®€åŒ–ï¼‰</span></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å®é™…éœ€è¦ï¼šold_log_probs, advantages, clip_epsilon ç­‰</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>            log_probs <span class="op">=</span> policy_model.compute_log_probs(prompt, response)</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>            policy_loss <span class="op">=</span> <span class="op">-</span>(log_probs <span class="op">*</span> reward).mean()</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># KL æ•£åº¦æƒ©ç½šï¼ˆé˜²æ­¢åç¦»å¤ªè¿œï¼‰</span></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>            ref_log_probs <span class="op">=</span> ref_model.compute_log_probs(prompt, response)</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>            kl_penalty <span class="op">=</span> (log_probs <span class="op">-</span> ref_log_probs).mean()</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> policy_loss <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> kl_penalty</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="é«˜æ•ˆå¾®è°ƒlora-å’Œ-peft" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="é«˜æ•ˆå¾®è°ƒlora-å’Œ-peft"><span class="header-section-number">14.8</span> 13.7 é«˜æ•ˆå¾®è°ƒï¼šLoRA å’Œ PEFT</h2>
<section id="ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒ" class="level3" data-number="14.8.1">
<h3 data-number="14.8.1" class="anchored" data-anchor-id="ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒ"><span class="header-section-number">14.8.1</span> ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦é«˜æ•ˆå¾®è°ƒï¼Ÿ</h3>
<pre><code>é—®é¢˜ï¼š
  å¤§æ¨¡å‹å…¨å‚æ•°å¾®è°ƒæˆæœ¬é«˜æ˜‚
  - GPT-3 (175B å‚æ•°)
  - éœ€è¦æ•°ç™¾ GB æ˜¾å­˜
  - è®­ç»ƒæ—¶é—´é•¿

è§£å†³ï¼š
  Parameter-Efficient Fine-Tuning (PEFT)
  - åªè®­ç»ƒå°‘é‡å‚æ•°
  - ä¿æŒæ€§èƒ½</code></pre>
<hr>
</section>
<section id="lora-low-rank-adaptation" class="level3" data-number="14.8.2">
<h3 data-number="14.8.2" class="anchored" data-anchor-id="lora-low-rank-adaptation"><span class="header-section-number">14.8.2</span> ğŸ”¹ LoRA (Low-Rank Adaptation)</h3>
<p><strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šä½ç§©åˆ†è§£</p>
<pre><code>åŸå§‹æƒé‡æ›´æ–°ï¼š
  W' = W + Î”W

LoRAï¼š
  W' = W + BA

  å…¶ä¸­ B âˆˆ â„^(dÃ—r), A âˆˆ â„^(rÃ—k), r &lt;&lt; min(d, k)

å‚æ•°é‡ï¼š
  åŸå§‹ï¼šd Ã— k
  LoRAï¼šr Ã— (d + k)  ï¼ˆå‡å°‘ &gt;90%ï¼‰</code></pre>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRALayer(nn.Module):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""LoRA å±‚"""</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, rank<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rank <span class="op">=</span> rank</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> alpha</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½ç§©çŸ©é˜µ</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_A <span class="op">=</span> nn.Parameter(torch.zeros(rank, in_features))</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora_B <span class="op">=</span> nn.Parameter(torch.zeros(out_features, rank))</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹åŒ–</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        nn.init.kaiming_uniform_(<span class="va">self</span>.lora_A, a<span class="op">=</span>math.sqrt(<span class="dv">5</span>))</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>        nn.init.zeros_(<span class="va">self</span>.lora_B)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç¼©æ”¾å› å­</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scaling <span class="op">=</span> alpha <span class="op">/</span> rank</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LoRA è·¯å¾„ï¼šx @ A^T @ B^T</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        lora_out <span class="op">=</span> (x <span class="op">@</span> <span class="va">self</span>.lora_A.T) <span class="op">@</span> <span class="va">self</span>.lora_B.T</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> lora_out <span class="op">*</span> <span class="va">self</span>.scaling</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LoRALinear(nn.Module):</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""å¸¦ LoRA çš„çº¿æ€§å±‚"""</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, linear_layer, rank<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å†»ç»“åŸå§‹æƒé‡</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> linear_layer</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.linear.parameters():</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ·»åŠ  LoRA</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lora <span class="op">=</span> LoRALayer(</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>            linear_layer.in_features,</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>            linear_layer.out_features,</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>            rank, alpha</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åŸå§‹è¾“å‡º + LoRA å¢é‡</span></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(x) <span class="op">+</span> <span class="va">self</span>.lora(x)</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== åº”ç”¨ LoRA ====================</span></span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_lora_to_model(model, rank<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="dv">16</span>, target_modules<span class="op">=</span>[<span class="st">'q_proj'</span>, <span class="st">'v_proj'</span>]):</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="co">    ä¸ºæ¨¡å‹æ·»åŠ  LoRA</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="co">    é€šå¸¸åªå¯¹ attention çš„ Q, V çŸ©é˜µæ·»åŠ  LoRA</span></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, module <span class="kw">in</span> model.named_modules():</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡æ¨¡å—</span></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">any</span>(target <span class="kw">in</span> name <span class="cf">for</span> target <span class="kw">in</span> target_modules):</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(module, nn.Linear):</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>                <span class="co"># æ›¿æ¢ä¸º LoRA ç‰ˆæœ¬</span></span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>                parent_name <span class="op">=</span> <span class="st">'.'</span>.join(name.split(<span class="st">'.'</span>)[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>                child_name <span class="op">=</span> name.split(<span class="st">'.'</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>                parent_module <span class="op">=</span> model.get_submodule(parent_name)</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>                lora_linear <span class="op">=</span> LoRALinear(module, rank, alpha)</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>                <span class="bu">setattr</span>(parent_module, child_name, lora_linear)</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Applied LoRA to </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== è®­ç»ƒ LoRA ====================</span></span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_with_lora(model, dataloader, num_epochs<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ä½¿ç”¨ LoRA å¾®è°ƒ"""</span></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åº”ç”¨ LoRA</span></span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> apply_lora_to_model(model)</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åªä¼˜åŒ– LoRA å‚æ•°</span></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>    lora_params <span class="op">=</span> [p <span class="cf">for</span> n, p <span class="kw">in</span> model.named_parameters() <span class="cf">if</span> <span class="st">'lora'</span> <span class="kw">in</span> n]</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(lora_params, lr<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Trainable params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> lora_params)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒå¾ªç¯ï¼ˆä¸æ™®é€šå¾®è°ƒç›¸åŒï¼‰</span></span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... è®­ç»ƒä»£ç </span></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="å…¶ä»–-peft-æ–¹æ³•" class="level3" data-number="14.8.3">
<h3 data-number="14.8.3" class="anchored" data-anchor-id="å…¶ä»–-peft-æ–¹æ³•"><span class="header-section-number">14.8.3</span> ğŸ”¹ å…¶ä»– PEFT æ–¹æ³•</h3>
<section id="adapter-tuning" class="level4" data-number="14.8.3.1">
<h4 data-number="14.8.3.1" class="anchored" data-anchor-id="adapter-tuning"><span class="header-section-number">14.8.3.1</span> <strong>Adapter Tuning</strong></h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Adapter(nn.Module):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Adapter æ¨¡å—"""</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size, bottleneck_size<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down_proj <span class="op">=</span> nn.Linear(hidden_size, bottleneck_size)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up_proj <span class="op">=</span> nn.Linear(bottleneck_size, hidden_size)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> nn.ReLU()</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        residual <span class="op">=</span> x</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.down_proj(x)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.activation(x)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.up_proj(x)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> residual  <span class="co"># æ®‹å·®è¿æ¥</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="prefix-tuning" class="level4" data-number="14.8.3.2">
<h4 data-number="14.8.3.2" class="anchored" data-anchor-id="prefix-tuning"><span class="header-section-number">14.8.3.2</span> <strong>Prefix Tuning</strong></h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PrefixTuning(nn.Module):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Prefix Tuning"""</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_prefix_tokens, d_model):</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¯å­¦ä¹ çš„ prefix embeddings</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prefix_embeddings <span class="op">=</span> nn.Parameter(</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>            torch.randn(num_prefix_tokens, d_model)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_embeddings):</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> input_embeddings.size(<span class="dv">0</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‰©å±• prefix åˆ° batch</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        prefix <span class="op">=</span> <span class="va">self</span>.prefix_embeddings.unsqueeze(<span class="dv">0</span>).expand(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‹¼æ¥åˆ°è¾“å…¥å‰é¢</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([prefix, input_embeddings], dim<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
</section>
<section id="llm-åº”ç”¨èŒƒå¼" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="llm-åº”ç”¨èŒƒå¼"><span class="header-section-number">14.9</span> 13.8 LLM åº”ç”¨èŒƒå¼</h2>
<section id="æ£€ç´¢å¢å¼ºç”Ÿæˆ-rag" class="level3" data-number="14.9.1">
<h3 data-number="14.9.1" class="anchored" data-anchor-id="æ£€ç´¢å¢å¼ºç”Ÿæˆ-rag"><span class="header-section-number">14.9.1</span> ğŸ”¹ æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)</h3>
<pre><code>RAG = Retrieval + Generation

æµç¨‹ï¼š
  1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
  2. å°†æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡
  3. ç”Ÿæˆç­”æ¡ˆ</code></pre>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RAGSystem:</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ"""</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, llm, retriever, top_k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.llm <span class="op">=</span> llm</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.retriever <span class="op">=</span> retriever</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.top_k <span class="op">=</span> top_k</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> answer_question(<span class="va">self</span>, question, knowledge_base):</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">        åŸºäºçŸ¥è¯†åº“å›ç­”é—®é¢˜</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°:</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">            question: ç”¨æˆ·é—®é¢˜</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">            knowledge_base: æ–‡æ¡£åˆ—è¡¨</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        relevant_docs <span class="op">=</span> <span class="va">self</span>.retriever.retrieve(</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>            question, knowledge_base, top_k<span class="op">=</span><span class="va">self</span>.top_k</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. æ„å»º prompt</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>.join([</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Document </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="sc">{</span>doc<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, doc <span class="kw">in</span> <span class="bu">enumerate</span>(relevant_docs)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"""Answer the question based on the context below.</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="ss">Context:</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a><span class="sc">{</span>context<span class="sc">}</span></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a><span class="ss">Question: </span><span class="sc">{</span>question<span class="sc">}</span></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a><span class="ss">Answer:"""</span></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. ç”Ÿæˆç­”æ¡ˆ</span></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        answer <span class="op">=</span> <span class="va">self</span>.llm.generate(prompt)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> answer, relevant_docs</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleRetriever:</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ç®€å•çš„åŸºäºåµŒå…¥çš„æ£€ç´¢å™¨"""</span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoder_model<span class="op">=</span><span class="st">'all-MiniLM-L6-v2'</span>):</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> SentenceTransformer(encoder_model)</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> retrieve(<span class="va">self</span>, query, documents, top_k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""</span></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç¼–ç </span></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a>        query_emb <span class="op">=</span> <span class="va">self</span>.encoder.encode([query])[<span class="dv">0</span>]</span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>        doc_embs <span class="op">=</span> <span class="va">self</span>.encoder.encode(documents)</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è®¡ç®—ç›¸ä¼¼åº¦</span></span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> cosine_similarity([query_emb], doc_embs)[<span class="dv">0</span>]</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è¿”å› top-k</span></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>        top_indices <span class="op">=</span> np.argsort(similarities)[<span class="op">-</span>top_k:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [documents[i] <span class="cf">for</span> i <span class="kw">in</span> top_indices]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="agent-ç³»ç»Ÿ" class="level3" data-number="14.9.2">
<h3 data-number="14.9.2" class="anchored" data-anchor-id="agent-ç³»ç»Ÿ"><span class="header-section-number">14.9.2</span> ğŸ”¹ Agent ç³»ç»Ÿ</h3>
<p>```python class LLMAgent: â€œâ€œâ€œåŸºäº LLM çš„ Agentâ€â€œâ€</p>
<pre><code>def __init__(self, llm, tools):
    self.llm = llm
    self.tools = {tool.name: tool for tool in tools}

def run(self, task, max_steps=5):
    """
    æ‰§è¡Œä»»åŠ¡

    æµç¨‹ï¼š
    1. æ€è€ƒä¸‹ä¸€æ­¥
    2. é€‰æ‹©å·¥å…·
    3. æ‰§è¡ŒåŠ¨ä½œ
    4. è§‚å¯Ÿç»“æœ
    5. é‡å¤ç›´åˆ°å®Œæˆ
    """

    history = []

    for step in range(max_steps):
        # æ„å»º prompt
        prompt = self._build_agent_prompt(task, history)

        # LLM å†³ç­–
        response = self.llm.generate(prompt)

        # è§£æåŠ¨ä½œ
        action = self._parse_action(response)

        if action['type'] == 'FINISH':
            return action['answer']

        # æ‰§è¡Œå·¥å…·
        tool_name = action['tool']
        tool_input = action['input']

        if tool_name in self.tools:
            observation = self.tools[tool_name].run(tool_input)
        else:
            observation = f"Tool {tool_name} not found."

        # è®°å½•
        history.append({
            'thought': action.get('tho</code></pre>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Chapter12.html" class="pagination-link" aria-label="ç¬¬åäºŒç« ï¼šå¯è§£é‡Šæ€§ä¸å¯¹æŠ—æ”»å‡»">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">ç¬¬åäºŒç« ï¼šå¯è§£é‡Šæ€§ä¸å¯¹æŠ—æ”»å‡»</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>