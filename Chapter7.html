<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks) â€“ æ·±åº¦å­¦ä¹ å®Œæ•´æ•™ç¨‹</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Chapter8.html" rel="next">
<link href="./Chapter6.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5ea8f22911a6df30576a2a25a24cdd7a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter5.html">ç¬¬äºŒéƒ¨åˆ†ï¼šè¿›é˜¶ç¯‡</a></li><li class="breadcrumb-item"><a href="./Chapter7.html"><span class="chapter-title">ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">æ·±åº¦å­¦ä¹ å®Œæ•´æ•™ç¨‹</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ğŸ“‹ è¯¾ç¨‹æ•´ä½“æ¡†æ¶</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€ç¯‡</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">æœºå™¨å­¦ä¹ å®Œæ•´è¯¾ç¨‹</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬äºŒç« ï¼šå›å½’ (Regression)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬ä¸‰ç« ï¼šåˆ†ç±»ä¸é€»è¾‘å›å½’ (Classification &amp; Logistic Regression)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬å››ç« ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåŸºç¡€ (Deep Neural Networks)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬äºŒéƒ¨åˆ†ï¼šè¿›é˜¶ç¯‡</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬äº”ç« ï¼šä¼˜åŒ–ç®—æ³•ä¸è®­ç»ƒæŠ€å·§ (Optimization &amp; Training Tricks)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬å…­ç« ï¼šå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter7.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬å…«ç« ï¼šAttention ä¸ Transformer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®è·µä¸åº”ç”¨</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬ä¹ç« ï¼šè¿ç§»å­¦ä¹ ä¸å¾®è°ƒ (Transfer Learning &amp; Fine-tuning)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬åç« ï¼šå¼ºåŒ–å­¦ä¹  (Reinforcement Learning)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter11.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬åä¸€ç« ï¼šæ— ç›‘ç£å­¦ä¹  (Unsupervised Learning)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter12.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬åäºŒç« ï¼šå¯è§£é‡Šæ€§ä¸å¯¹æŠ—æ”»å‡»</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Chapter13.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">ç¬¬åä¸‰ç« ï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶ä»£</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#ç« èŠ‚ç›®æ ‡" id="toc-ç« èŠ‚ç›®æ ‡" class="nav-link active" data-scroll-target="#ç« èŠ‚ç›®æ ‡">ğŸ“Œ ç« èŠ‚ç›®æ ‡</a></li>
  <li><a href="#ä¸ºä»€ä¹ˆéœ€è¦-rnn" id="toc-ä¸ºä»€ä¹ˆéœ€è¦-rnn" class="nav-link" data-scroll-target="#ä¸ºä»€ä¹ˆéœ€è¦-rnn">7.1 ä¸ºä»€ä¹ˆéœ€è¦ RNNï¼Ÿ</a>
  <ul class="collapse">
  <li><a href="#åºåˆ—æ•°æ®çš„ç‰¹æ€§" id="toc-åºåˆ—æ•°æ®çš„ç‰¹æ€§" class="nav-link" data-scroll-target="#åºåˆ—æ•°æ®çš„ç‰¹æ€§">ğŸ¯ åºåˆ—æ•°æ®çš„ç‰¹æ€§</a></li>
  <li><a href="#cnn-å’Œ-fc-çš„å±€é™" id="toc-cnn-å’Œ-fc-çš„å±€é™" class="nav-link" data-scroll-target="#cnn-å’Œ-fc-çš„å±€é™">âŒ CNN å’Œ FC çš„å±€é™</a></li>
  <li><a href="#rnn-çš„ä¼˜åŠ¿" id="toc-rnn-çš„ä¼˜åŠ¿" class="nav-link" data-scroll-target="#rnn-çš„ä¼˜åŠ¿">âœ… RNN çš„ä¼˜åŠ¿</a></li>
  </ul></li>
  <li><a href="#åŸºæœ¬-rnn-vanilla-rnn" id="toc-åŸºæœ¬-rnn-vanilla-rnn" class="nav-link" data-scroll-target="#åŸºæœ¬-rnn-vanilla-rnn">7.2 åŸºæœ¬ RNN (Vanilla RNN)</a>
  <ul class="collapse">
  <li><a href="#rnn-çš„å¾ªç¯ç»“æ„" id="toc-rnn-çš„å¾ªç¯ç»“æ„" class="nav-link" data-scroll-target="#rnn-çš„å¾ªç¯ç»“æ„">ğŸ”„ RNN çš„å¾ªç¯ç»“æ„</a></li>
  <li><a href="#rnn-è®¡ç®—" id="toc-rnn-è®¡ç®—" class="nav-link" data-scroll-target="#rnn-è®¡ç®—">ğŸ“ RNN è®¡ç®—</a></li>
  <li><a href="#ä»é›¶å®ç°-rnn" id="toc-ä»é›¶å®ç°-rnn" class="nav-link" data-scroll-target="#ä»é›¶å®ç°-rnn">ğŸ’» ä»é›¶å®ç° RNN</a></li>
  </ul></li>
  <li><a href="#æ¢¯åº¦é—®é¢˜æ¶ˆå¤±å’Œçˆ†ç‚¸" id="toc-æ¢¯åº¦é—®é¢˜æ¶ˆå¤±å’Œçˆ†ç‚¸" class="nav-link" data-scroll-target="#æ¢¯åº¦é—®é¢˜æ¶ˆå¤±å’Œçˆ†ç‚¸">7.3 æ¢¯åº¦é—®é¢˜ï¼šæ¶ˆå¤±å’Œçˆ†ç‚¸</a>
  <ul class="collapse">
  <li><a href="#æ¢¯åº¦æ¶ˆå¤±-vanishing-gradient" id="toc-æ¢¯åº¦æ¶ˆå¤±-vanishing-gradient" class="nav-link" data-scroll-target="#æ¢¯åº¦æ¶ˆå¤±-vanishing-gradient">ğŸš¨ æ¢¯åº¦æ¶ˆå¤± (Vanishing Gradient)</a></li>
  <li><a href="#æ¢¯åº¦çˆ†ç‚¸-exploding-gradient" id="toc-æ¢¯åº¦çˆ†ç‚¸-exploding-gradient" class="nav-link" data-scroll-target="#æ¢¯åº¦çˆ†ç‚¸-exploding-gradient">ğŸ’¥ æ¢¯åº¦çˆ†ç‚¸ (Exploding Gradient)</a></li>
  <li><a href="#è§£å†³æ–¹æ¡ˆ" id="toc-è§£å†³æ–¹æ¡ˆ" class="nav-link" data-scroll-target="#è§£å†³æ–¹æ¡ˆ">âœ… è§£å†³æ–¹æ¡ˆ</a></li>
  </ul></li>
  <li><a href="#lstm-long-short-term-memory" id="toc-lstm-long-short-term-memory" class="nav-link" data-scroll-target="#lstm-long-short-term-memory">7.4 LSTM (Long Short-Term Memory) â­</a>
  <ul class="collapse">
  <li><a href="#æ ¸å¿ƒæ€æƒ³" id="toc-æ ¸å¿ƒæ€æƒ³" class="nav-link" data-scroll-target="#æ ¸å¿ƒæ€æƒ³">ğŸ¯ æ ¸å¿ƒæ€æƒ³</a></li>
  <li><a href="#lstm-çš„å››ä¸ªé—¨" id="toc-lstm-çš„å››ä¸ªé—¨" class="nav-link" data-scroll-target="#lstm-çš„å››ä¸ªé—¨">ğŸ“ LSTM çš„å››ä¸ªé—¨</a></li>
  <li><a href="#lstm-å•å…ƒå›¾" id="toc-lstm-å•å…ƒå›¾" class="nav-link" data-scroll-target="#lstm-å•å…ƒå›¾">ğŸ“Š LSTM å•å…ƒå›¾</a></li>
  <li><a href="#pytorch-å®ç°" id="toc-pytorch-å®ç°" class="nav-link" data-scroll-target="#pytorch-å®ç°">ğŸ’» PyTorch å®ç°</a></li>
  </ul></li>
  <li><a href="#gru-gated-recurrent-unit" id="toc-gru-gated-recurrent-unit" class="nav-link" data-scroll-target="#gru-gated-recurrent-unit">7.5 GRU (Gated Recurrent Unit)</a>
  <ul class="collapse">
  <li><a href="#ç®€åŒ–çš„-lstm" id="toc-ç®€åŒ–çš„-lstm" class="nav-link" data-scroll-target="#ç®€åŒ–çš„-lstm">ğŸ¯ ç®€åŒ–çš„ LSTM</a></li>
  <li><a href="#gru-çš„ä¸¤ä¸ªé—¨" id="toc-gru-çš„ä¸¤ä¸ªé—¨" class="nav-link" data-scroll-target="#gru-çš„ä¸¤ä¸ªé—¨">ğŸ“ GRU çš„ä¸¤ä¸ªé—¨</a></li>
  <li><a href="#lstm-vs-gru" id="toc-lstm-vs-gru" class="nav-link" data-scroll-target="#lstm-vs-gru">ğŸ“Š LSTM vs GRU</a></li>
  <li><a href="#å®ç°" id="toc-å®ç°" class="nav-link" data-scroll-target="#å®ç°">ğŸ’» å®ç°</a></li>
  </ul></li>
  <li><a href="#åŒå‘-rnn-bidirectional-rnn" id="toc-åŒå‘-rnn-bidirectional-rnn" class="nav-link" data-scroll-target="#åŒå‘-rnn-bidirectional-rnn">7.6 åŒå‘ RNN (Bidirectional RNN)</a>
  <ul class="collapse">
  <li><a href="#é—®é¢˜å‰å‘-rnn-çš„å±€é™" id="toc-é—®é¢˜å‰å‘-rnn-çš„å±€é™" class="nav-link" data-scroll-target="#é—®é¢˜å‰å‘-rnn-çš„å±€é™">ğŸ¯ é—®é¢˜ï¼šå‰å‘ RNN çš„å±€é™</a></li>
  <li><a href="#åŒå‘-rnn-è§£å†³" id="toc-åŒå‘-rnn-è§£å†³" class="nav-link" data-scroll-target="#åŒå‘-rnn-è§£å†³">âœ… åŒå‘ RNN è§£å†³</a></li>
  <li><a href="#å®ç°-1" id="toc-å®ç°-1" class="nav-link" data-scroll-target="#å®ç°-1">ğŸ’» å®ç°</a></li>
  </ul></li>
  <li><a href="#å®æˆ˜-1æ–‡æœ¬æƒ…æ„Ÿåˆ†æ" id="toc-å®æˆ˜-1æ–‡æœ¬æƒ…æ„Ÿåˆ†æ" class="nav-link" data-scroll-target="#å®æˆ˜-1æ–‡æœ¬æƒ…æ„Ÿåˆ†æ">7.7 å®æˆ˜ 1ï¼šæ–‡æœ¬æƒ…æ„Ÿåˆ†æ</a>
  <ul class="collapse">
  <li><a href="#ä»»åŠ¡è®¾å®š" id="toc-ä»»åŠ¡è®¾å®š" class="nav-link" data-scroll-target="#ä»»åŠ¡è®¾å®š">ğŸ“‹ ä»»åŠ¡è®¾å®š</a></li>
  <li><a href="#å®Œæ•´å®ç°" id="toc-å®Œæ•´å®ç°" class="nav-link" data-scroll-target="#å®Œæ•´å®ç°">ğŸ’» å®Œæ•´å®ç°</a></li>
  </ul></li>
  <li><a href="#å®æˆ˜-2æ—¶é—´åºåˆ—é¢„æµ‹" id="toc-å®æˆ˜-2æ—¶é—´åºåˆ—é¢„æµ‹" class="nav-link" data-scroll-target="#å®æˆ˜-2æ—¶é—´åºåˆ—é¢„æµ‹">7.8 å®æˆ˜ 2ï¼šæ—¶é—´åºåˆ—é¢„æµ‹</a>
  <ul class="collapse">
  <li><a href="#ä»»åŠ¡é¢„æµ‹è‚¡ç¥¨ä»·æ ¼" id="toc-ä»»åŠ¡é¢„æµ‹è‚¡ç¥¨ä»·æ ¼" class="nav-link" data-scroll-target="#ä»»åŠ¡é¢„æµ‹è‚¡ç¥¨ä»·æ ¼">ğŸ“‹ ä»»åŠ¡ï¼šé¢„æµ‹è‚¡ç¥¨ä»·æ ¼</a></li>
  </ul></li>
  <li><a href="#å®æˆ˜-3åºåˆ—åˆ°åºåˆ—-seq2seq" id="toc-å®æˆ˜-3åºåˆ—åˆ°åºåˆ—-seq2seq" class="nav-link" data-scroll-target="#å®æˆ˜-3åºåˆ—åˆ°åºåˆ—-seq2seq">7.9 å®æˆ˜ 3ï¼šåºåˆ—åˆ°åºåˆ— (Seq2Seq)</a>
  <ul class="collapse">
  <li><a href="#ä»»åŠ¡æœºå™¨ç¿»è¯‘" id="toc-ä»»åŠ¡æœºå™¨ç¿»è¯‘" class="nav-link" data-scroll-target="#ä»»åŠ¡æœºå™¨ç¿»è¯‘">ğŸ“‹ ä»»åŠ¡ï¼šæœºå™¨ç¿»è¯‘</a></li>
  </ul></li>
  <li><a href="#æœ¬ç« ä½œä¸š" id="toc-æœ¬ç« ä½œä¸š" class="nav-link" data-scroll-target="#æœ¬ç« ä½œä¸š">ğŸ“ æœ¬ç« ä½œä¸š</a>
  <ul class="collapse">
  <li><a href="#ä½œä¸š-1rnn-æ¢¯åº¦åˆ†æ" id="toc-ä½œä¸š-1rnn-æ¢¯åº¦åˆ†æ" class="nav-link" data-scroll-target="#ä½œä¸š-1rnn-æ¢¯åº¦åˆ†æ">ä½œä¸š 1ï¼šRNN æ¢¯åº¦åˆ†æ</a></li>
  <li><a href="#ä½œä¸š-2æƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®" id="toc-ä½œä¸š-2æƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®" class="nav-link" data-scroll-target="#ä½œä¸š-2æƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®">ä½œä¸š 2ï¼šæƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®</a></li>
  <li><a href="#ä½œä¸š-3æ–‡æœ¬ç”Ÿæˆ" id="toc-ä½œä¸š-3æ–‡æœ¬ç”Ÿæˆ" class="nav-link" data-scroll-target="#ä½œä¸š-3æ–‡æœ¬ç”Ÿæˆ">ä½œä¸š 3ï¼šæ–‡æœ¬ç”Ÿæˆ</a></li>
  </ul></li>
  <li><a href="#æœ¬ç« å…³é”®æ¦‚å¿µ" id="toc-æœ¬ç« å…³é”®æ¦‚å¿µ" class="nav-link" data-scroll-target="#æœ¬ç« å…³é”®æ¦‚å¿µ">ğŸ”‘ æœ¬ç« å…³é”®æ¦‚å¿µ</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Chapter5.html">ç¬¬äºŒéƒ¨åˆ†ï¼šè¿›é˜¶ç¯‡</a></li><li class="breadcrumb-item"><a href="./Chapter7.html"><span class="chapter-title">ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks)</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">ç¬¬ä¸ƒç« ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ (Recurrent Neural Networks)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="ç« èŠ‚ç›®æ ‡" class="level2">
<h2 class="anchored" data-anchor-id="ç« èŠ‚ç›®æ ‡">ğŸ“Œ ç« èŠ‚ç›®æ ‡</h2>
<ul>
<li>ç†è§£åºåˆ—æ•°æ®å’Œå¾ªç¯ç»“æ„</li>
<li>æŒæ¡åŸºæœ¬ RNN åŠå…¶æ¢¯åº¦é—®é¢˜</li>
<li>æ·±å…¥å­¦ä¹  LSTM å’Œ GRU çš„è®¾è®¡</li>
<li>äº†è§£åŒå‘ RNN å’Œå¤šå±‚ RNN</li>
<li>å®æˆ˜ï¼šæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€åºåˆ—é¢„æµ‹</li>
</ul>
<hr>
</section>
<section id="ä¸ºä»€ä¹ˆéœ€è¦-rnn" class="level2">
<h2 class="anchored" data-anchor-id="ä¸ºä»€ä¹ˆéœ€è¦-rnn">7.1 ä¸ºä»€ä¹ˆéœ€è¦ RNNï¼Ÿ</h2>
<section id="åºåˆ—æ•°æ®çš„ç‰¹æ€§" class="level3">
<h3 class="anchored" data-anchor-id="åºåˆ—æ•°æ®çš„ç‰¹æ€§">ğŸ¯ åºåˆ—æ•°æ®çš„ç‰¹æ€§</h3>
<p><strong>ä»€ä¹ˆæ˜¯åºåˆ—æ•°æ®ï¼Ÿ</strong></p>
<pre><code>æ™®é€šæ•°æ®ï¼ˆç‹¬ç«‹ï¼‰ï¼š
  å›¾ç‰‡ã€æˆ¿ä»·ã€åŒ»å­¦è¯Šæ–­
  æ¯ä¸ªæ ·æœ¬æ˜¯ç‹¬ç«‹çš„

åºåˆ—æ•°æ®ï¼ˆæœ‰ä¾èµ–ï¼‰ï¼š
  æ–‡æœ¬ï¼šä»Šå¤©å¤©æ°”â†’å¾ˆå¥½â†’é€‚åˆâ†’å‡ºå»
  è¯­éŸ³ï¼šéŸ³é¢‘å¸§ tâ‚, tâ‚‚, ..., tâ‚™
  æ—¶é—´åºåˆ—ï¼šè‚¡ç¥¨ä»·æ ¼ã€æ¸©åº¦è®°å½•

ç‰¹æ€§ï¼š
  âœ“ é•¿åº¦å¯å˜
  âœ“ å‰åæœ‰ä¾èµ–å…³ç³»
  âœ“ é¡ºåºå¾ˆé‡è¦</code></pre>
</section>
<section id="cnn-å’Œ-fc-çš„å±€é™" class="level3">
<h3 class="anchored" data-anchor-id="cnn-å’Œ-fc-çš„å±€é™">âŒ CNN å’Œ FC çš„å±€é™</h3>
<p><strong>å…¨è¿æ¥ç½‘ç»œ</strong>ï¼š - å›ºå®šè¾“å…¥å¤§å° - å¿½è§†åºåˆ—é¡ºåº - æ— æ³•å¤„ç†å¯å˜é•¿åº¦</p>
<p><strong>CNN</strong>ï¼š - è™½ç„¶æœ‰å±€éƒ¨è¿æ¥ï¼Œä½†æ„Ÿå—é‡æœ‰é™ - éœ€è¦å¾ˆå¤šå±‚æ‰èƒ½æ•è·é•¿è·ç¦»ä¾èµ– - ä¸å¤Ÿè‡ªç„¶</p>
</section>
<section id="rnn-çš„ä¼˜åŠ¿" class="level3">
<h3 class="anchored" data-anchor-id="rnn-çš„ä¼˜åŠ¿">âœ… RNN çš„ä¼˜åŠ¿</h3>
<pre><code>è®¾è®¡ç”¨äºåºåˆ—æ•°æ®ï¼š
  âœ“ å¯å˜é•¿åº¦è¾“å…¥
  âœ“ å¾ªç¯ç»“æ„ä¿ç•™åºåˆ—ä¿¡æ¯
  âœ“ å‚æ•°å…±äº«ï¼ˆæ‰€æœ‰æ—¶é—´æ­¥å…±ç”¨ï¼‰
  âœ“ å¯ä»¥å»ºæ¨¡é•¿æœŸä¾èµ–ï¼ˆç†è®ºä¸Šï¼‰</code></pre>
<hr>
</section>
</section>
<section id="åŸºæœ¬-rnn-vanilla-rnn" class="level2">
<h2 class="anchored" data-anchor-id="åŸºæœ¬-rnn-vanilla-rnn">7.2 åŸºæœ¬ RNN (Vanilla RNN)</h2>
<section id="rnn-çš„å¾ªç¯ç»“æ„" class="level3">
<h3 class="anchored" data-anchor-id="rnn-çš„å¾ªç¯ç»“æ„">ğŸ”„ RNN çš„å¾ªç¯ç»“æ„</h3>
<p><strong>å±•å¼€è§†å›¾</strong>ï¼š</p>
<pre><code>yâ‚      yâ‚‚      yâ‚ƒ      yâ‚„
â†‘       â†‘       â†‘       â†‘
hâ‚      hâ‚‚      hâ‚ƒ      hâ‚„
â†‘       â†‘       â†‘       â†‘
xâ‚  â†’  hâ‚  â†’  hâ‚‚  â†’  hâ‚ƒ  â†’  hâ‚„
        â†“       â†“       â†“
        (å¾ªç¯)

éšè—çŠ¶æ€ä½œä¸ºä¿¡æ¯è½½ä½“ä¼ é€’</code></pre>
<p><strong>æŠ˜å è§†å›¾</strong>ï¼ˆå‚æ•°å…±äº«ï¼‰ï¼š</p>
<pre><code>      x(t)
        â†“
    [U]  [W]  [V]
      â†“    â†“    â†“
   h(t-1) â†’ RNN â†’ h(t) â†’ y(t)
            å•å…ƒ</code></pre>
</section>
<section id="rnn-è®¡ç®—" class="level3">
<h3 class="anchored" data-anchor-id="rnn-è®¡ç®—">ğŸ“ RNN è®¡ç®—</h3>
<p><strong>å•æ—¶åˆ»è®¡ç®—</strong>ï¼š</p>
<pre><code>h(t) = tanh(UÂ·x(t) + WÂ·h(t-1) + b)
y(t) = VÂ·h(t) + c

æˆ–ç”¨æ¿€æ´»å‡½æ•° Ïƒï¼š
h(t) = Ïƒ(UÂ·x(t) + WÂ·h(t-1) + b)</code></pre>
<p><strong>ç¬¦å·è¯´æ˜</strong>ï¼š - <code>x(t)</code>: t æ—¶åˆ»çš„è¾“å…¥ - <code>h(t)</code>: t æ—¶åˆ»çš„éšè—çŠ¶æ€ - <code>y(t)</code>: t æ—¶åˆ»çš„è¾“å‡º - <code>U</code>: è¾“å…¥åˆ°éšè—çš„æƒé‡ - <code>W</code>: éšè—åˆ°éšè—çš„æƒé‡ï¼ˆå¾ªç¯ï¼‰ - <code>V</code>: éšè—åˆ°è¾“å‡ºçš„æƒé‡ - <code>b, c</code>: åç½®</p>
</section>
<section id="ä»é›¶å®ç°-rnn" class="level3">
<h3 class="anchored" data-anchor-id="ä»é›¶å®ç°-rnn">ğŸ’» ä»é›¶å®ç° RNN</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VanillaRNN:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                 learning_rate<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> input_size</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_size <span class="op">=</span> output_size</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹åŒ–æƒé‡</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.U <span class="op">=</span> np.random.randn(hidden_size, input_size) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.random.randn(hidden_size, hidden_size) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.V <span class="op">=</span> np.random.randn(output_size, hidden_size) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> np.zeros((hidden_size, <span class="dv">1</span>))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c <span class="op">=</span> np.zeros((output_size, <span class="dv">1</span>))</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">        å‰å‘ä¼ æ’­</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co">            X: åºåˆ—è¾“å…¥ [(seq_len, input_size), ...]</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co">        è¿”å›ï¼š</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co">            Y: è¾“å‡ºåºåˆ—</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co">            cache: ç”¨äºåå‘ä¼ æ’­çš„ä¸­é—´å€¼</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        seq_len <span class="op">=</span> <span class="bu">len</span>(X)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹åŒ–éšè—çŠ¶æ€</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> np.zeros((<span class="va">self</span>.hidden_size, <span class="dv">1</span>))</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å­˜å‚¨ä¸­é—´å€¼</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        cache <span class="op">=</span> {</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X'</span>: X,</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">'h'</span>: [h],  <span class="co"># åŒ…æ‹¬åˆå§‹ h</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">'z'</span>: [],</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">'y'</span>: []</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(seq_len):</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># éšè—çŠ¶æ€è®¡ç®—</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> <span class="va">self</span>.U <span class="op">@</span> X[t] <span class="op">+</span> <span class="va">self</span>.W <span class="op">@</span> h <span class="op">+</span> <span class="va">self</span>.b</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> np.tanh(z)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è¾“å‡ºè®¡ç®—</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> <span class="va">self</span>.V <span class="op">@</span> h <span class="op">+</span> <span class="va">self</span>.c</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ä¿å­˜ä¸­é—´å€¼</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>            cache[<span class="st">'z'</span>].append(z)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>            cache[<span class="st">'h'</span>].append(h)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            cache[<span class="st">'y'</span>].append(y)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.array(cache[<span class="st">'y'</span>]), cache</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, dY, cache):</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="co">        åå‘ä¼ æ’­ï¼ˆBPTTï¼‰</span></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a><span class="co">            dY: è¾“å‡ºæ¢¯åº¦ [(output_size, 1), ...]</span></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="co">            cache: å‰å‘ä¼ æ’­çš„ä¸­é—´å€¼</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>        seq_len <span class="op">=</span> <span class="bu">len</span>(dY)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹åŒ–æ¢¯åº¦</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        dU <span class="op">=</span> np.zeros_like(<span class="va">self</span>.U)</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>        dW <span class="op">=</span> np.zeros_like(<span class="va">self</span>.W)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>        dV <span class="op">=</span> np.zeros_like(<span class="va">self</span>.V)</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> np.zeros_like(<span class="va">self</span>.b)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>        dc <span class="op">=</span> np.zeros_like(<span class="va">self</span>.c)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹éšè—çŠ¶æ€æ¢¯åº¦</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        dh_next <span class="op">=</span> np.zeros((<span class="va">self</span>.hidden_size, <span class="dv">1</span>))</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åå‘éå†æ—¶é—´æ­¥</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(seq_len)):</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è¾“å‡ºå±‚æ¢¯åº¦</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>            dV <span class="op">+=</span> dY[t] <span class="op">@</span> cache[<span class="st">'h'</span>][t<span class="op">+</span><span class="dv">1</span>].T</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>            dc <span class="op">+=</span> dY[t]</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>            <span class="co"># éšè—å±‚æ¢¯åº¦</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>            dh <span class="op">=</span> <span class="va">self</span>.V.T <span class="op">@</span> dY[t] <span class="op">+</span> dh_next</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>            <span class="co"># tanh çš„æ¢¯åº¦</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>            dz <span class="op">=</span> dh <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> np.tanh(cache[<span class="st">'z'</span>][t])<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æƒé‡æ¢¯åº¦</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>            dU <span class="op">+=</span> dz <span class="op">@</span> cache[<span class="st">'X'</span>][t].T</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>            dW <span class="op">+=</span> dz <span class="op">@</span> cache[<span class="st">'h'</span>][t].T</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>            db <span class="op">+=</span> dz</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ä¼ é€’åˆ°å‰ä¸€æ—¶åˆ»</span></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>            dh_next <span class="op">=</span> <span class="va">self</span>.W.T <span class="op">@</span> dz</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰</span></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dparam <span class="kw">in</span> [dU, dW, dV, db, dc]:</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>            np.clip(dparam, <span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, out<span class="op">=</span>dparam)</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> dU, dW, dV, db, dc</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_parameters(<span class="va">self</span>, dU, dW, dV, db, dc):</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""æ›´æ–°å‚æ•°"""</span></span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.U <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dU</span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dW</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.V <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dV</span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> db</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c <span class="op">-=</span> <span class="va">self</span>.learning_rate <span class="op">*</span> dc</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="co"># ç¤ºä¾‹ï¼šé¢„æµ‹æ•°å­—åºåˆ—</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_rnn():</span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è¶…å‚æ•°</span></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>    input_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>    hidden_size <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>    output_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>    seq_len <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>    rnn <span class="op">=</span> VanillaRNN(input_size, hidden_size, output_size,</span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>                     learning_rate<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç”Ÿæˆç®€å•æ•°æ®ï¼ˆt æ—¶åˆ»é¢„æµ‹ t+1ï¼‰</span></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> [np.array([[i]]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)]</span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> [np.array([[i<span class="op">+</span><span class="dv">1</span>]]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)]</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒ</span></span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>        Y_pred, cache <span class="op">=</span> rnn.forward(X_train)</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è®¡ç®—æŸå¤±</span></span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> np.mean((Y_pred <span class="op">-</span> np.array(y_train))<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ¢¯åº¦è®¡ç®—</span></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>        dY <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (Y_pred <span class="op">-</span> np.array(y_train)) <span class="op">/</span> <span class="bu">len</span>(y_train)</span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>        dU, dW, dV, db, dc <span class="op">=</span> rnn.backward(dY, cache)</span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ›´æ–°å‚æ•°</span></span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>        rnn.update_parameters(dU, dW, dV, db, dc)</span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">: Loss = </span><span class="sc">{</span>loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>train_rnn()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="æ¢¯åº¦é—®é¢˜æ¶ˆå¤±å’Œçˆ†ç‚¸" class="level2">
<h2 class="anchored" data-anchor-id="æ¢¯åº¦é—®é¢˜æ¶ˆå¤±å’Œçˆ†ç‚¸">7.3 æ¢¯åº¦é—®é¢˜ï¼šæ¶ˆå¤±å’Œçˆ†ç‚¸</h2>
<section id="æ¢¯åº¦æ¶ˆå¤±-vanishing-gradient" class="level3">
<h3 class="anchored" data-anchor-id="æ¢¯åº¦æ¶ˆå¤±-vanishing-gradient">ğŸš¨ æ¢¯åº¦æ¶ˆå¤± (Vanishing Gradient)</h3>
<p><strong>é—®é¢˜</strong>ï¼šé•¿æœŸä¾èµ–éš¾ä»¥å­¦ä¹ </p>
<pre><code>h(t) = tanh(UÂ·x(t) + WÂ·h(t-1) + b)

âˆ‚h(t)/âˆ‚h(t-1) = WÂ·diag(1 - tanhÂ²(...))

å¯¹ t æ­¥ä¹‹å‰çš„æ¢¯åº¦ï¼š
âˆ‚h(T)/âˆ‚h(t) = âˆ(Ï„=t+1 to T) [WÂ·diag(1-tanhÂ²(...))]

å¦‚æœ ||W|| &lt; 1ï¼Œåˆ™ï¼š
||âˆ‚h(T)/âˆ‚h(t)|| â‰ˆ ||W||^(T-t)

T-t å¾ˆå¤§æ—¶ï¼Œæ¢¯åº¦æ¥è¿‘ 0 â†’ æ¢¯åº¦æ¶ˆå¤±</code></pre>
<p><strong>åæœ</strong>ï¼š - æ—©æœŸæƒé‡å‡ ä¹ä¸æ›´æ–° - æ— æ³•å­¦ä¹ é•¿æœŸä¾èµ–</p>
</section>
<section id="æ¢¯åº¦çˆ†ç‚¸-exploding-gradient" class="level3">
<h3 class="anchored" data-anchor-id="æ¢¯åº¦çˆ†ç‚¸-exploding-gradient">ğŸ’¥ æ¢¯åº¦çˆ†ç‚¸ (Exploding Gradient)</h3>
<p><strong>é—®é¢˜</strong>ï¼šå¦‚æœ ||W|| &gt; 1</p>
<pre><code>æ¢¯åº¦ âˆ ||W||^(T-t) â†’ âˆ

å¯¼è‡´ï¼š
- å‚æ•°æ›´æ–°ä¸ç¨³å®š
- NaN/Inf å€¼
- è®­ç»ƒå´©æºƒ</code></pre>
</section>
<section id="è§£å†³æ–¹æ¡ˆ" class="level3">
<h3 class="anchored" data-anchor-id="è§£å†³æ–¹æ¡ˆ">âœ… è§£å†³æ–¹æ¡ˆ</h3>
<section id="æ¢¯åº¦è£å‰ª-gradient-clipping" class="level4">
<h4 class="anchored" data-anchor-id="æ¢¯åº¦è£å‰ª-gradient-clipping"><strong>1. æ¢¯åº¦è£å‰ª (Gradient Clipping)</strong></h4>
<p><strong>é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clip_gradients(gradients, max_norm<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">    L2 èŒƒæ•°è£å‰ª</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    total_norm <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> g <span class="kw">in</span> gradients:</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        total_norm <span class="op">+=</span> np.<span class="bu">sum</span>(g<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    total_norm <span class="op">=</span> np.sqrt(total_norm)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    clip_ratio <span class="op">=</span> max_norm <span class="op">/</span> (total_norm <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    clip_ratio <span class="op">=</span> <span class="bu">min</span>(clip_ratio, <span class="fl">1.0</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    clipped_grads <span class="op">=</span> []</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> g <span class="kw">in</span> gradients:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        clipped_grads.append(g <span class="op">*</span> clip_ratio)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> clipped_grads</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="æƒé‡åˆå§‹åŒ–" class="level4">
<h4 class="anchored" data-anchor-id="æƒé‡åˆå§‹åŒ–"><strong>2. æƒé‡åˆå§‹åŒ–</strong></h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># æ­£äº¤åˆå§‹åŒ–</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> orthogonal_init(shape):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""æ­£äº¤åˆå§‹åŒ– W çŸ©é˜µ"""</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    Q, R <span class="op">=</span> np.linalg.qr(np.random.randn(<span class="op">*</span>shape))</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Q</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ä½¿ç”¨</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> orthogonal_init((hidden_size, hidden_size))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="æ¿€æ´»å‡½æ•°é€‰æ‹©" class="level4">
<h4 class="anchored" data-anchor-id="æ¿€æ´»å‡½æ•°é€‰æ‹©"><strong>3. æ¿€æ´»å‡½æ•°é€‰æ‹©</strong></h4>
<pre><code>ReLU çš„æ¢¯åº¦æ’ä¸º 1ï¼ˆåœ¨æ­£åŒºåŸŸï¼‰
ä¸å®¹æ˜“æ¢¯åº¦æ¶ˆå¤±

tanh çš„æ¢¯åº¦æœ€å¤§ä¸º 0.25
å®¹æ˜“æ¢¯åº¦æ¶ˆå¤±</code></pre>
<hr>
</section>
</section>
</section>
<section id="lstm-long-short-term-memory" class="level2">
<h2 class="anchored" data-anchor-id="lstm-long-short-term-memory">7.4 LSTM (Long Short-Term Memory) â­</h2>
<section id="æ ¸å¿ƒæ€æƒ³" class="level3">
<h3 class="anchored" data-anchor-id="æ ¸å¿ƒæ€æƒ³">ğŸ¯ æ ¸å¿ƒæ€æƒ³</h3>
<p><strong>ä½¿ç”¨â€è®°å¿†å•å…ƒâ€ä»£æ›¿éšè—çŠ¶æ€</strong></p>
<pre><code>ä¼ ç»Ÿ RNNï¼š
  ä¿¡æ¯é€šè¿‡éšè—çŠ¶æ€ä¼ é€’
  æ¯æ­¥éƒ½è¢«ç ´åæ€§åœ°æ”¹å˜

LSTMï¼š
  æœ‰ä¸“é—¨çš„"ç»†èƒçŠ¶æ€"C(t)
  ä¿¡æ¯å¯ä»¥é•¿æœŸä¿ç•™
  é€šè¿‡é—¨æ§æœºåˆ¶æœ‰é€‰æ‹©åœ°æ›´æ–°</code></pre>
</section>
<section id="lstm-çš„å››ä¸ªé—¨" class="level3">
<h3 class="anchored" data-anchor-id="lstm-çš„å››ä¸ªé—¨">ğŸ“ LSTM çš„å››ä¸ªé—¨</h3>
<p><strong>1. é—å¿˜é—¨ (Forget Gate)</strong></p>
<pre><code>f(t) = Ïƒ(W_fÂ·[h(t-1), x(t)] + b_f)

ä½œç”¨ï¼šå†³å®šå“ªäº›ä¿¡æ¯è¢«ä¸¢å¼ƒ
f(t) â‰ˆ 0: ä¸¢å¼ƒ
f(t) â‰ˆ 1: ä¿ç•™</code></pre>
<p><strong>2. è¾“å…¥é—¨ (Input Gate)</strong></p>
<pre><code>i(t) = Ïƒ(W_iÂ·[h(t-1), x(t)] + b_i)
CÌƒ(t) = tanh(W_cÂ·[h(t-1), x(t)] + b_c)

ä½œç”¨ï¼šå†³å®šæ–°ä¿¡æ¯
i(t): æœ‰å¤šå°‘æ–°ä¿¡æ¯è¿›å…¥
CÌƒ(t): æ–°ä¿¡æ¯çš„å†…å®¹</code></pre>
<p><strong>3. ç»†èƒçŠ¶æ€æ›´æ–° (Cell State Update)</strong></p>
<pre><code>C(t) = f(t) âŠ™ C(t-1) + i(t) âŠ™ CÌƒ(t)

âŠ™ è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ï¼ˆHadamard ç§¯ï¼‰

è¿‡ç¨‹ï¼š
  å‰ä¸€ä¸ªç»†èƒçŠ¶æ€ Ã— é—å¿˜é—¨
  + æ–°ä¿¡æ¯ Ã— è¾“å…¥é—¨</code></pre>
<p><strong>4. è¾“å‡ºé—¨ (Output Gate)</strong></p>
<pre><code>o(t) = Ïƒ(W_oÂ·[h(t-1), x(t)] + b_o)
h(t) = o(t) âŠ™ tanh(C(t))

ä½œç”¨ï¼šå†³å®šè¾“å‡ºå¤šå°‘ä¿¡æ¯</code></pre>
</section>
<section id="lstm-å•å…ƒå›¾" class="level3">
<h3 class="anchored" data-anchor-id="lstm-å•å…ƒå›¾">ğŸ“Š LSTM å•å…ƒå›¾</h3>
<pre><code>        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ç»†èƒçŠ¶æ€ C(t)      â”‚ â† é•¿æœŸè®°å¿†
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚   âŠ™ f(t)    â”‚ â† é—å¿˜é—¨ï¼ˆä¿ç•™å¤šå°‘ï¼‰
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ âŠ™ + âŠ™ i(t) CÌƒ(t) â”‚ â† æ–°ä¿¡æ¯åŠ å…¥
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ tanh âŠ™ o(t) â”‚ â† è¾“å‡ºé—¨
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
            h(t) â† çŸ­æœŸè®°å¿†</code></pre>
</section>
<section id="pytorch-å®ç°" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-å®ç°">ğŸ’» PyTorch å®ç°</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># æ–¹å¼1ï¼šä½¿ç”¨é«˜çº§ LSTM</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LSTMModel(nn.Module):</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, num_layers, output_size):</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LSTMModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> num_layers</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM å±‚</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>            input_size<span class="op">=</span>input_size,</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>            hidden_size<span class="op">=</span>hidden_size,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>            num_layers<span class="op">=</span>num_layers,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span>,  <span class="co"># è¾“å…¥æ ¼å¼ (batch, seq, feature)</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span><span class="fl">0.3</span> <span class="cf">if</span> num_layers <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è¾“å‡ºå±‚</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_size, output_size)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch_size, seq_len, input_size)</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM è¾“å‡º</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        lstm_out, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># lstm_out: (batch, seq_len, hidden_size)</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># h_n: (num_layers, batch, hidden_size)</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># c_n: (num_layers, batch, hidden_size)</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶åˆ»çš„è¾“å‡º</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        last_out <span class="op">=</span> lstm_out[:, <span class="op">-</span><span class="dv">1</span>, :]  <span class="co"># (batch, hidden_size)</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…¨è¿æ¥å±‚</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(last_out)  <span class="co"># (batch, output_size)</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="co"># æ–¹å¼2ï¼šä»é›¶å®ç° LSTM å•å…ƒ</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LSTMCell(nn.Module):</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size):</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LSTMCell, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> input_size</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å››ä¸ªé—¨çš„æƒé‡çŸ©é˜µ</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_f <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_i <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_c <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_o <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, h_prev, c_prev):</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, input_size)</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a><span class="co">            h_prev: (batch, hidden_size)</span></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="co">            c_prev: (batch, hidden_size)</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="co">        è¿”å›ï¼š</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="co">            h: (batch, hidden_size)</span></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a><span class="co">            c: (batch, hidden_size)</span></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‹¼æ¥è¾“å…¥å’Œå‰ä¸€éšè—çŠ¶æ€</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([x, h_prev], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å››ä¸ªé—¨</span></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.W_f(combined))  <span class="co"># é—å¿˜é—¨</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.W_i(combined))  <span class="co"># è¾“å…¥é—¨</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>        c_tilde <span class="op">=</span> torch.tanh(<span class="va">self</span>.W_c(combined))  <span class="co"># å€™é€‰å€¼</span></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.W_o(combined))  <span class="co"># è¾“å‡ºé—¨</span></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ›´æ–°ç»†èƒçŠ¶æ€</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> f <span class="op">*</span> c_prev <span class="op">+</span> i <span class="op">*</span> c_tilde</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è®¡ç®—éšè—çŠ¶æ€</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> o <span class="op">*</span> torch.tanh(c)</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h, c</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a><span class="co"># ä½¿ç”¨è‡ªå®šä¹‰ LSTM Cell</span></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomLSTM(nn.Module):</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size, num_layers<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(CustomLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> num_layers</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¤šå±‚ LSTM</span></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm_cells <span class="op">=</span> nn.ModuleList([</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>            LSTMCell(</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>                input_size <span class="cf">if</span> layer <span class="op">==</span> <span class="dv">0</span> <span class="cf">else</span> hidden_size,</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>                hidden_size</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(num_layers)</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_size, output_size)</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, seq_len, input_size)</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>        batch_size, seq_len, _ <span class="op">=</span> x.size()</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åˆå§‹åŒ–éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€</span></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> [torch.zeros(batch_size, <span class="va">self</span>.hidden_size)</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>             <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers)]</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> [torch.zeros(batch_size, <span class="va">self</span>.hidden_size)</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>             <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers)]</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(seq_len):</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> x[:, t, :]  <span class="co"># (batch, input_size)</span></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers):</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>                h[layer], c[layer] <span class="op">=</span> <span class="va">self</span>.lstm_cells[layer](</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>                    x_t, h[layer], c[layer]</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>                x_t <span class="op">=</span> h[layer]</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶åˆ»çš„éšè—çŠ¶æ€</span></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(h[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="gru-gated-recurrent-unit" class="level2">
<h2 class="anchored" data-anchor-id="gru-gated-recurrent-unit">7.5 GRU (Gated Recurrent Unit)</h2>
<section id="ç®€åŒ–çš„-lstm" class="level3">
<h3 class="anchored" data-anchor-id="ç®€åŒ–çš„-lstm">ğŸ¯ ç®€åŒ–çš„ LSTM</h3>
<p><strong>LSTM é—®é¢˜</strong>ï¼šå‚æ•°å¤šï¼Œè®¡ç®—å¤æ‚</p>
<p><strong>GRU è§£å†³</strong>ï¼šåªç”¨ä¸¤ä¸ªé—¨ï¼Œç»“æ„æ›´ç®€æ´</p>
</section>
<section id="gru-çš„ä¸¤ä¸ªé—¨" class="level3">
<h3 class="anchored" data-anchor-id="gru-çš„ä¸¤ä¸ªé—¨">ğŸ“ GRU çš„ä¸¤ä¸ªé—¨</h3>
<p><strong>1. é‡ç½®é—¨ (Reset Gate)</strong></p>
<pre><code>r(t) = Ïƒ(W_rÂ·[h(t-1), x(t)] + b_r)

ä½œç”¨ï¼šå†³å®šæœ‰å¤šå°‘å†å²ä¿¡æ¯è¢«é—å¿˜</code></pre>
<p><strong>2. æ›´æ–°é—¨ (Update Gate)</strong></p>
<pre><code>z(t) = Ïƒ(W_zÂ·[h(t-1), x(t)] + b_z)

ä½œç”¨ï¼šå†³å®šæ–°æ—§ä¿¡æ¯çš„æ¯”ä¾‹</code></pre>
<p><strong>3. å€™é€‰éšè—çŠ¶æ€</strong></p>
<pre><code>hÌƒ(t) = tanh(WÂ·[r(t) âŠ™ h(t-1), x(t)] + b)

ä½¿ç”¨é‡ç½®é—¨æ¥é€‰æ‹©å†å²ä¿¡æ¯</code></pre>
<p><strong>4. éšè—çŠ¶æ€æ›´æ–°</strong></p>
<pre><code>h(t) = (1 - z(t)) âŠ™ hÌƒ(t) + z(t) âŠ™ h(t-1)

= æ–°ä¿¡æ¯æ¯”ä¾‹ Ã— å€™é€‰å€¼ + å†å²ä¿¡æ¯æ¯”ä¾‹ Ã— å‰å€¼</code></pre>
</section>
<section id="lstm-vs-gru" class="level3">
<h3 class="anchored" data-anchor-id="lstm-vs-gru">ğŸ“Š LSTM vs GRU</h3>
<pre><code>LSTMï¼š
  - ç»†èƒçŠ¶æ€ C(t) ç”¨äºé•¿æœŸè®°å¿†
  - éšè—çŠ¶æ€ h(t) ç”¨äºçŸ­æœŸè¾“å‡º
  - 3ä¸ªé—¨ï¼ˆé—å¿˜ã€è¾“å…¥ã€è¾“å‡ºï¼‰
  - å‚æ•°å¤šï¼Œè¡¨è¾¾èƒ½åŠ›å¼º

GRUï¼š
  - ç»†èƒçŠ¶æ€å’Œéšè—çŠ¶æ€åˆå¹¶
  - 2ä¸ªé—¨ï¼ˆé‡ç½®ã€æ›´æ–°ï¼‰
  - å‚æ•°å°‘ï¼ˆçº¦ LSTM çš„ 2/3ï¼‰
  - è®¡ç®—é€Ÿåº¦å¿«
  - åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šæ€§èƒ½ç›¸å½“</code></pre>
</section>
<section id="å®ç°" class="level3">
<h3 class="anchored" data-anchor-id="å®ç°">ğŸ’» å®ç°</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GRUCell(nn.Module):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(GRUCell, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> input_size</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é‡ç½®é—¨å’Œæ›´æ–°é—¨</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_r <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_z <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å€™é€‰éšè—çŠ¶æ€</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_h <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, hidden_size)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, h_prev):</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, input_size)</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">            h_prev: (batch, hidden_size)</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="co">        è¿”å›ï¼š</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="co">            h: (batch, hidden_size)</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([x, h_prev], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é‡ç½®é—¨</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        r <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.W_r(combined))</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ›´æ–°é—¨</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.W_z(combined))</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å€™é€‰éšè—çŠ¶æ€</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        combined_reset <span class="op">=</span> torch.cat([x, r <span class="op">*</span> h_prev], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        h_tilde <span class="op">=</span> torch.tanh(<span class="va">self</span>.W_h(combined_reset))</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ›´æ–°éšè—çŠ¶æ€</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> z) <span class="op">*</span> h_tilde <span class="op">+</span> z <span class="op">*</span> h_prev</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="co"># PyTorch é«˜çº§æ¥å£</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.GRU(</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    input_size<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    hidden_size<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>    num_layers<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="åŒå‘-rnn-bidirectional-rnn" class="level2">
<h2 class="anchored" data-anchor-id="åŒå‘-rnn-bidirectional-rnn">7.6 åŒå‘ RNN (Bidirectional RNN)</h2>
<section id="é—®é¢˜å‰å‘-rnn-çš„å±€é™" class="level3">
<h3 class="anchored" data-anchor-id="é—®é¢˜å‰å‘-rnn-çš„å±€é™">ğŸ¯ é—®é¢˜ï¼šå‰å‘ RNN çš„å±€é™</h3>
<pre><code>å‰å‘ RNNï¼š
  xâ‚ â†’ xâ‚‚ â†’ xâ‚ƒ â†’ xâ‚„

hâ‚ƒ æ— æ³•çœ‹åˆ° xâ‚„ çš„ä¿¡æ¯
ä½†æœ‰äº›ä»»åŠ¡éœ€è¦å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼</code></pre>
</section>
<section id="åŒå‘-rnn-è§£å†³" class="level3">
<h3 class="anchored" data-anchor-id="åŒå‘-rnn-è§£å†³">âœ… åŒå‘ RNN è§£å†³</h3>
<p><strong>åŒæ—¶è¿è¡Œå‰å‘å’Œåå‘ RNN</strong></p>
<pre><code>å‰å‘ï¼šxâ‚ â†’ xâ‚‚ â†’ xâ‚ƒ â†’ xâ‚„
      â†’hâ‚â†’ â†’hâ‚‚â†’ â†’hâ‚ƒâ†’ â†’hâ‚„

åå‘ï¼š        â† â† â† â†
      â†hÌ„â‚â†  â†hÌ„â‚‚â†  â†hÌ„â‚ƒâ†  â†hÌ„â‚„â†

è¾“å‡ºï¼š[hâ‚ƒ, hÌ„â‚ƒ] = ç»“åˆä¸¤ä¸ªæ–¹å‘çš„ä¿¡æ¯</code></pre>
<p><strong>è®¡ç®—</strong>ï¼š</p>
<pre><code>hâ‚ƒ = [hâ‚ƒ_forward, hâ‚ƒ_backward]
   = [LSTM_fwd(xâ‚:xâ‚ƒ), LSTM_bwd(xâ‚ƒ:xâ‚)]</code></pre>
</section>
<section id="å®ç°-1" class="level3">
<h3 class="anchored" data-anchor-id="å®ç°-1">ğŸ’» å®ç°</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BiLSTM(nn.Module):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, num_layers, output_size):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(BiLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>            input_size<span class="op">=</span>input_size,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>            hidden_size<span class="op">=</span>hidden_size,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>            num_layers<span class="op">=</span>num_layers,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>            bidirectional<span class="op">=</span><span class="va">True</span>  <span class="co"># å…³é”®ï¼</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åŒå‘ LSTM è¾“å‡ºå¤§å°æ˜¯ 2Ã—hidden_size</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_size <span class="op">*</span> <span class="dv">2</span>, output_size)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, seq_len, input_size)</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM è¾“å‡º</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        lstm_out, _ <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># lstm_out: (batch, seq_len, 2Ã—hidden_size)</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½¿ç”¨æœ€åæ—¶åˆ»</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>        last_out <span class="op">=</span> lstm_out[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(last_out)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a><span class="co"># æˆ–è€…ç”¨æ‰€æœ‰æ—¶åˆ»ï¼ˆå¦‚ NER æ ‡ç­¾ï¼‰</span></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BiLSTMSequence(nn.Module):</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size, output_size):</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_size, hidden_size,</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>                           batch_first<span class="op">=</span><span class="va">True</span>, bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_size <span class="op">*</span> <span class="dv">2</span>, output_size)</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>        lstm_out, _ <span class="op">=</span> <span class="va">self</span>.lstm(x)  <span class="co"># (batch, seq, 2Ã—hidden)</span></span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¯¹æ¯ä¸ªæ—¶åˆ»åšåˆ†ç±»</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(lstm_out)  <span class="co"># (batch, seq, output_size)</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="å®æˆ˜-1æ–‡æœ¬æƒ…æ„Ÿåˆ†æ" class="level2">
<h2 class="anchored" data-anchor-id="å®æˆ˜-1æ–‡æœ¬æƒ…æ„Ÿåˆ†æ">7.7 å®æˆ˜ 1ï¼šæ–‡æœ¬æƒ…æ„Ÿåˆ†æ</h2>
<section id="ä»»åŠ¡è®¾å®š" class="level3">
<h3 class="anchored" data-anchor-id="ä»»åŠ¡è®¾å®š">ğŸ“‹ ä»»åŠ¡è®¾å®š</h3>
<p><strong>æ•°æ®</strong>ï¼šç”µå½±è¯„è®º</p>
<pre><code>"è¿™éƒ¨ç”µå½±å¤ªæ£’äº†ï¼" â†’ æ­£é¢ (1)
"å®Œå…¨æ˜¯æµªè´¹æ—¶é—´ã€‚" â†’ è´Ÿé¢ (0)</code></pre>
</section>
<section id="å®Œæ•´å®ç°" class="level3">
<h3 class="anchored" data-anchor-id="å®Œæ•´å®ç°">ğŸ’» å®Œæ•´å®ç°</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== æ•°æ®é¢„å¤„ç† ====================</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Tokenizer:</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size<span class="op">=</span><span class="dv">5000</span>):</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vocab_size <span class="op">=</span> vocab_size</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.word2idx <span class="op">=</span> {<span class="st">'&lt;PAD&gt;'</span>: <span class="dv">0</span>, <span class="st">'&lt;UNK&gt;'</span>: <span class="dv">1</span>}</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.idx2word <span class="op">=</span> {<span class="dv">0</span>: <span class="st">'&lt;PAD&gt;'</span>, <span class="dv">1</span>: <span class="st">'&lt;UNK&gt;'</span>}</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build_vocab(<span class="va">self</span>, texts):</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""æ„å»ºè¯æ±‡è¡¨"""</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        word_freq <span class="op">=</span> Counter()</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>            words <span class="op">=</span> <span class="va">self</span>.tokenize(text)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>            word_freq.update(words)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word, freq <span class="kw">in</span> word_freq.most_common(<span class="va">self</span>.vocab_size <span class="op">-</span> <span class="dv">2</span>):</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.word2idx[word] <span class="op">=</span> idx</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.idx2word[idx] <span class="op">=</span> word</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tokenize(<span class="va">self</span>, text):</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""åˆ†è¯"""</span></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> text.lower()</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-z</span><span class="dv">\s</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">''</span>, text)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> text.split()</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, text, max_len<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""ç¼–ç æ–‡æœ¬"""</span></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> <span class="va">self</span>.tokenize(text)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        ids <span class="op">=</span> [<span class="va">self</span>.word2idx.get(w, <span class="dv">1</span>) <span class="cf">for</span> w <span class="kw">in</span> words]</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Padding æˆ–æˆªæ–­</span></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(ids) <span class="op">&lt;</span> max_len:</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>            ids <span class="op">=</span> ids <span class="op">+</span> [<span class="dv">0</span>] <span class="op">*</span> (max_len <span class="op">-</span> <span class="bu">len</span>(ids))</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>            ids <span class="op">=</span> ids[:max_len]</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ids</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, ids):</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""è§£ç """</span></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">' '</span>.join([<span class="va">self</span>.idx2word.get(i, <span class="st">'&lt;UNK&gt;'</span>) <span class="cf">for</span> i <span class="kw">in</span> ids])</span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== æ¨¡å‹å®šä¹‰ ====================</span></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SentimentLSTM(nn.Module):</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vocab_size, embedding_size, hidden_size,</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>                 num_layers<span class="op">=</span><span class="dv">2</span>, dropout<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SentimentLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding å±‚</span></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(vocab_size, embedding_size,</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>                                     padding_idx<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM å±‚</span></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(</span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>            input_size<span class="op">=</span>embedding_size,</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>            hidden_size<span class="op">=</span>hidden_size,</span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>            num_layers<span class="op">=</span>num_layers,</span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span>dropout,</span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>            bidirectional<span class="op">=</span><span class="va">True</span></span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¯é€‰ï¼‰</span></span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> nn.MultiheadAttention(</span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>            embed_dim<span class="op">=</span>hidden_size <span class="op">*</span> <span class="dv">2</span>,</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>            num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span>dropout</span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…¨è¿æ¥å±‚</span></span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(hidden_size <span class="op">*</span> <span class="dv">2</span>, <span class="dv">128</span>)</span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>)</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Batch Normalization</span></span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bn <span class="op">=</span> nn.BatchNorm1d(<span class="dv">128</span>)</span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, seq_len)</span></span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding</span></span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>        embedded <span class="op">=</span> <span class="va">self</span>.embedding(x)  <span class="co"># (batch, seq_len, embedding_size)</span></span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM</span></span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>        lstm_out, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.lstm(embedded)</span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># lstm_out: (batch, seq_len, hidden_size*2)</span></span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶</span></span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>        attn_out, attn_weights <span class="op">=</span> <span class="va">self</span>.attention(</span>
<span id="cb30-104"><a href="#cb30-104" aria-hidden="true" tabindex="-1"></a>            lstm_out, lstm_out, lstm_out</span>
<span id="cb30-105"><a href="#cb30-105" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-106"><a href="#cb30-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-107"><a href="#cb30-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å–æœ€åä¸€ä¸ªæ—¶åˆ»æˆ–æ± åŒ–</span></span>
<span id="cb30-108"><a href="#cb30-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ–¹å¼1ï¼šæœ€åæ—¶åˆ»</span></span>
<span id="cb30-109"><a href="#cb30-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># last_hidden = lstm_out[:, -1, :]</span></span>
<span id="cb30-110"><a href="#cb30-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-111"><a href="#cb30-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ–¹å¼2ï¼šå¹³å‡æ± åŒ–</span></span>
<span id="cb30-112"><a href="#cb30-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># last_hidden = torch.mean(lstm_out, dim=1)</span></span>
<span id="cb30-113"><a href="#cb30-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-114"><a href="#cb30-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ–¹å¼3ï¼šæœ€å¤§æ± åŒ–</span></span>
<span id="cb30-115"><a href="#cb30-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># last_hidden, _ = torch.max(lstm_out, dim=1)</span></span>
<span id="cb30-116"><a href="#cb30-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-117"><a href="#cb30-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ–¹å¼4ï¼šä½¿ç”¨æ³¨æ„åŠ›è¾“å‡º</span></span>
<span id="cb30-118"><a href="#cb30-118" aria-hidden="true" tabindex="-1"></a>        last_hidden <span class="op">=</span> torch.mean(attn_out, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-119"><a href="#cb30-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-120"><a href="#cb30-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…¨è¿æ¥å±‚</span></span>
<span id="cb30-121"><a href="#cb30-121" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(last_hidden))</span>
<span id="cb30-122"><a href="#cb30-122" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.bn(x)</span>
<span id="cb30-123"><a href="#cb30-123" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout(x)</span>
<span id="cb30-124"><a href="#cb30-124" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb30-125"><a href="#cb30-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-126"><a href="#cb30-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(x)</span>
<span id="cb30-127"><a href="#cb30-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-128"><a href="#cb30-128" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== è®­ç»ƒä»£ç  ====================</span></span>
<span id="cb30-129"><a href="#cb30-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-130"><a href="#cb30-130" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_sentiment_model():</span>
<span id="cb30-131"><a href="#cb30-131" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è¶…å‚æ•°</span></span>
<span id="cb30-132"><a href="#cb30-132" aria-hidden="true" tabindex="-1"></a>    VOCAB_SIZE <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb30-133"><a href="#cb30-133" aria-hidden="true" tabindex="-1"></a>    EMBEDDING_SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb30-134"><a href="#cb30-134" aria-hidden="true" tabindex="-1"></a>    HIDDEN_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb30-135"><a href="#cb30-135" aria-hidden="true" tabindex="-1"></a>    NUM_LAYERS <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb30-136"><a href="#cb30-136" aria-hidden="true" tabindex="-1"></a>    MAX_LEN <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb30-137"><a href="#cb30-137" aria-hidden="true" tabindex="-1"></a>    BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb30-138"><a href="#cb30-138" aria-hidden="true" tabindex="-1"></a>    EPOCHS <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb30-139"><a href="#cb30-139" aria-hidden="true" tabindex="-1"></a>    LEARNING_RATE <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb30-140"><a href="#cb30-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-141"><a href="#cb30-141" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb30-142"><a href="#cb30-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-143"><a href="#cb30-143" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç¤ºä¾‹æ•°æ®ï¼ˆå®é™…åº”ä½¿ç”¨çœŸå®æ•°æ®é›†å¦‚ IMDBï¼‰</span></span>
<span id="cb30-144"><a href="#cb30-144" aria-hidden="true" tabindex="-1"></a>    texts_train <span class="op">=</span> [</span>
<span id="cb30-145"><a href="#cb30-145" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This movie is great and wonderful"</span>,</span>
<span id="cb30-146"><a href="#cb30-146" aria-hidden="true" tabindex="-1"></a>        <span class="st">"I love this film so much"</span>,</span>
<span id="cb30-147"><a href="#cb30-147" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Amazing performance by the actors"</span>,</span>
<span id="cb30-148"><a href="#cb30-148" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Terrible waste of time"</span>,</span>
<span id="cb30-149"><a href="#cb30-149" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Boring and dull movie"</span>,</span>
<span id="cb30-150"><a href="#cb30-150" aria-hidden="true" tabindex="-1"></a>        <span class="st">"I hate this film"</span></span>
<span id="cb30-151"><a href="#cb30-151" aria-hidden="true" tabindex="-1"></a>    ] <span class="op">*</span> <span class="dv">100</span>  <span class="co"># å¤åˆ¶ä»¥å¢åŠ æ•°æ®é‡</span></span>
<span id="cb30-152"><a href="#cb30-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-153"><a href="#cb30-153" aria-hidden="true" tabindex="-1"></a>    labels_train <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>] <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb30-154"><a href="#cb30-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-155"><a href="#cb30-155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ„å»ºè¯æ±‡è¡¨</span></span>
<span id="cb30-156"><a href="#cb30-156" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> Tokenizer(vocab_size<span class="op">=</span>VOCAB_SIZE)</span>
<span id="cb30-157"><a href="#cb30-157" aria-hidden="true" tabindex="-1"></a>    tokenizer.build_vocab(texts_train)</span>
<span id="cb30-158"><a href="#cb30-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-159"><a href="#cb30-159" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç¼–ç æ•°æ®</span></span>
<span id="cb30-160"><a href="#cb30-160" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> torch.tensor([tokenizer.encode(t, MAX_LEN) <span class="cf">for</span> t <span class="kw">in</span> texts_train])</span>
<span id="cb30-161"><a href="#cb30-161" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> torch.tensor(labels_train, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb30-162"><a href="#cb30-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-163"><a href="#cb30-163" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ•°æ®åŠ è½½å™¨</span></span>
<span id="cb30-164"><a href="#cb30-164" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> TensorDataset(X_train, y_train)</span>
<span id="cb30-165"><a href="#cb30-165" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-166"><a href="#cb30-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-167"><a href="#cb30-167" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ¨¡å‹</span></span>
<span id="cb30-168"><a href="#cb30-168" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SentimentLSTM(</span>
<span id="cb30-169"><a href="#cb30-169" aria-hidden="true" tabindex="-1"></a>        vocab_size<span class="op">=</span>VOCAB_SIZE,</span>
<span id="cb30-170"><a href="#cb30-170" aria-hidden="true" tabindex="-1"></a>        embedding_size<span class="op">=</span>EMBEDDING_SIZE,</span>
<span id="cb30-171"><a href="#cb30-171" aria-hidden="true" tabindex="-1"></a>        hidden_size<span class="op">=</span>HIDDEN_SIZE,</span>
<span id="cb30-172"><a href="#cb30-172" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span>NUM_LAYERS</span>
<span id="cb30-173"><a href="#cb30-173" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb30-174"><a href="#cb30-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-175"><a href="#cb30-175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æŸå¤±å’Œä¼˜åŒ–å™¨</span></span>
<span id="cb30-176"><a href="#cb30-176" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.BCELoss()</span>
<span id="cb30-177"><a href="#cb30-177" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>LEARNING_RATE, weight_decay<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb30-178"><a href="#cb30-178" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> optim.lr_scheduler.ReduceLROnPlateau(</span>
<span id="cb30-179"><a href="#cb30-179" aria-hidden="true" tabindex="-1"></a>        optimizer, mode<span class="op">=</span><span class="st">'min'</span>, patience<span class="op">=</span><span class="dv">3</span>, factor<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb30-180"><a href="#cb30-180" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-181"><a href="#cb30-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-182"><a href="#cb30-182" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒ</span></span>
<span id="cb30-183"><a href="#cb30-183" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCHS):</span>
<span id="cb30-184"><a href="#cb30-184" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb30-185"><a href="#cb30-185" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-186"><a href="#cb30-186" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-187"><a href="#cb30-187" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-188"><a href="#cb30-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-189"><a href="#cb30-189" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb30-190"><a href="#cb30-190" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_batch.to(device)</span>
<span id="cb30-191"><a href="#cb30-191" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb30-192"><a href="#cb30-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-193"><a href="#cb30-193" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb30-194"><a href="#cb30-194" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(X_batch)</span>
<span id="cb30-195"><a href="#cb30-195" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, y_batch)</span>
<span id="cb30-196"><a href="#cb30-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-197"><a href="#cb30-197" aria-hidden="true" tabindex="-1"></a>            <span class="co"># åå‘ä¼ æ’­</span></span>
<span id="cb30-198"><a href="#cb30-198" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb30-199"><a href="#cb30-199" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb30-200"><a href="#cb30-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-201"><a href="#cb30-201" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ¢¯åº¦è£å‰ª</span></span>
<span id="cb30-202"><a href="#cb30-202" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb30-203"><a href="#cb30-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-204"><a href="#cb30-204" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb30-205"><a href="#cb30-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-206"><a href="#cb30-206" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ç»Ÿè®¡</span></span>
<span id="cb30-207"><a href="#cb30-207" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb30-208"><a href="#cb30-208" aria-hidden="true" tabindex="-1"></a>            predicted <span class="op">=</span> (outputs <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb30-209"><a href="#cb30-209" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (predicted <span class="op">==</span> y_batch).<span class="bu">sum</span>().item()</span>
<span id="cb30-210"><a href="#cb30-210" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> y_batch.size(<span class="dv">0</span>)</span>
<span id="cb30-211"><a href="#cb30-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-212"><a href="#cb30-212" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb30-213"><a href="#cb30-213" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> correct <span class="op">/</span> total</span>
<span id="cb30-214"><a href="#cb30-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-215"><a href="#cb30-215" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Epoch [</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>EPOCHS<span class="sc">}</span><span class="ss">], Loss: </span><span class="sc">{</span>avg_loss<span class="sc">:.4f}</span><span class="ss">, Acc: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">%'</span>)</span>
<span id="cb30-216"><a href="#cb30-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-217"><a href="#cb30-217" aria-hidden="true" tabindex="-1"></a>        scheduler.step(avg_loss)</span>
<span id="cb30-218"><a href="#cb30-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-219"><a href="#cb30-219" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ä¿å­˜æ¨¡å‹</span></span>
<span id="cb30-220"><a href="#cb30-220" aria-hidden="true" tabindex="-1"></a>    torch.save(model.state_dict(), <span class="st">'sentiment_lstm.pth'</span>)</span>
<span id="cb30-221"><a href="#cb30-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-222"><a href="#cb30-222" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, tokenizer</span>
<span id="cb30-223"><a href="#cb30-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-224"><a href="#cb30-224" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== é¢„æµ‹å‡½æ•° ====================</span></span>
<span id="cb30-225"><a href="#cb30-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-226"><a href="#cb30-226" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_sentiment(model, tokenizer, text, device):</span>
<span id="cb30-227"><a href="#cb30-227" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""é¢„æµ‹å•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ"""</span></span>
<span id="cb30-228"><a href="#cb30-228" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb30-229"><a href="#cb30-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-230"><a href="#cb30-230" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç¼–ç </span></span>
<span id="cb30-231"><a href="#cb30-231" aria-hidden="true" tabindex="-1"></a>    encoded <span class="op">=</span> tokenizer.encode(text, max_len<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb30-232"><a href="#cb30-232" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.tensor([encoded]).to(device)</span>
<span id="cb30-233"><a href="#cb30-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-234"><a href="#cb30-234" aria-hidden="true" tabindex="-1"></a>    <span class="co"># é¢„æµ‹</span></span>
<span id="cb30-235"><a href="#cb30-235" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-236"><a href="#cb30-236" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(x)</span>
<span id="cb30-237"><a href="#cb30-237" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> output.item()</span>
<span id="cb30-238"><a href="#cb30-238" aria-hidden="true" tabindex="-1"></a>        sentiment <span class="op">=</span> <span class="st">"æ­£é¢"</span> <span class="cf">if</span> prob <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="st">"è´Ÿé¢"</span></span>
<span id="cb30-239"><a href="#cb30-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-240"><a href="#cb30-240" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentiment, prob</span>
<span id="cb30-241"><a href="#cb30-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-242"><a href="#cb30-242" aria-hidden="true" tabindex="-1"></a><span class="co"># ä½¿ç”¨</span></span>
<span id="cb30-243"><a href="#cb30-243" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb30-244"><a href="#cb30-244" aria-hidden="true" tabindex="-1"></a>    model, tokenizer <span class="op">=</span> train_sentiment_model()</span>
<span id="cb30-245"><a href="#cb30-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-246"><a href="#cb30-246" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æµ‹è¯•</span></span>
<span id="cb30-247"><a href="#cb30-247" aria-hidden="true" tabindex="-1"></a>    test_texts <span class="op">=</span> [</span>
<span id="cb30-248"><a href="#cb30-248" aria-hidden="true" tabindex="-1"></a>        <span class="st">"This is an amazing movie!"</span>,</span>
<span id="cb30-249"><a href="#cb30-249" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Terrible and boring film."</span>,</span>
<span id="cb30-250"><a href="#cb30-250" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Not bad, quite enjoyable."</span></span>
<span id="cb30-251"><a href="#cb30-251" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb30-252"><a href="#cb30-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-253"><a href="#cb30-253" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb30-254"><a href="#cb30-254" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb30-255"><a href="#cb30-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-256"><a href="#cb30-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> test_texts:</span>
<span id="cb30-257"><a href="#cb30-257" aria-hidden="true" tabindex="-1"></a>        sentiment, prob <span class="op">=</span> predict_sentiment(model, tokenizer, text, device)</span>
<span id="cb30-258"><a href="#cb30-258" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">æ–‡æœ¬: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb30-259"><a href="#cb30-259" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"æƒ…æ„Ÿ: </span><span class="sc">{</span>sentiment<span class="sc">}</span><span class="ss"> (ç½®ä¿¡åº¦: </span><span class="sc">{</span>prob<span class="sc">:.4f}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="å®æˆ˜-2æ—¶é—´åºåˆ—é¢„æµ‹" class="level2">
<h2 class="anchored" data-anchor-id="å®æˆ˜-2æ—¶é—´åºåˆ—é¢„æµ‹">7.8 å®æˆ˜ 2ï¼šæ—¶é—´åºåˆ—é¢„æµ‹</h2>
<section id="ä»»åŠ¡é¢„æµ‹è‚¡ç¥¨ä»·æ ¼" class="level3">
<h3 class="anchored" data-anchor-id="ä»»åŠ¡é¢„æµ‹è‚¡ç¥¨ä»·æ ¼">ğŸ“‹ ä»»åŠ¡ï¼šé¢„æµ‹è‚¡ç¥¨ä»·æ ¼</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== æ•°æ®å‡†å¤‡ ====================</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_sequences(data, seq_length):</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co">    åˆ›å»ºåºåˆ—æ•°æ®</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co">    å‚æ•°ï¼š</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co">        data: åŸå§‹æ•°æ® (n_samples,)</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co">        seq_length: åºåˆ—é•¿åº¦</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="co">    è¿”å›ï¼š</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="co">        X: (n_samples - seq_length, seq_length, 1)</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co">        y: (n_samples - seq_length, 1)</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> [], []</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data) <span class="op">-</span> seq_length):</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        X.append(data[i:i<span class="op">+</span>seq_length])</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        y.append(data[i<span class="op">+</span>seq_length])</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(X), np.array(y)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="co"># ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”ä½¿ç”¨çœŸå®è‚¡ç¥¨æ•°æ®ï¼‰</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_stock_data(n_samples<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨ä»·æ ¼"""</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">100</span>, n_samples)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è¶‹åŠ¿ + å­£èŠ‚æ€§ + å™ªå£°</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    trend <span class="op">=</span> <span class="fl">0.02</span> <span class="op">*</span> t</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    seasonal <span class="op">=</span> <span class="dv">10</span> <span class="op">*</span> np.sin(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> t <span class="op">/</span> <span class="dv">50</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> np.random.randn(n_samples) <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    price <span class="op">=</span> <span class="dv">100</span> <span class="op">+</span> trend <span class="op">+</span> seasonal <span class="op">+</span> noise</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> price</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== æ¨¡å‹å®šä¹‰ ====================</span></span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> StockLSTM(nn.Module):</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size<span class="op">=</span><span class="dv">1</span>, hidden_size<span class="op">=</span><span class="dv">64</span>, num_layers<span class="op">=</span><span class="dv">2</span>, dropout<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(StockLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> num_layers</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM å±‚</span></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>            input_size<span class="op">=</span>input_size,</span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>            hidden_size<span class="op">=</span>hidden_size,</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>            num_layers<span class="op">=</span>num_layers,</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>            dropout<span class="op">=</span>dropout <span class="cf">if</span> num_layers <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…¨è¿æ¥å±‚</span></span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Sequential(</span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_size, <span class="dv">32</span>),</span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout),</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>)</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="co">            x: (batch, seq_len, input_size)</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># LSTM</span></span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>        lstm_out, _ <span class="op">=</span> <span class="va">self</span>.lstm(x)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å–æœ€åä¸€ä¸ªæ—¶åˆ»</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>        last_out <span class="op">=</span> lstm_out[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é¢„æµ‹</span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fc(last_out)</span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================== è®­ç»ƒä»£ç  ====================</span></span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_stock_predictor():</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è¶…å‚æ•°</span></span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>    SEQ_LENGTH <span class="op">=</span> <span class="dv">30</span>  <span class="co"># ä½¿ç”¨30å¤©é¢„æµ‹ä¸‹ä¸€å¤©</span></span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>    BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>    EPOCHS <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>    LEARNING_RATE <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç”Ÿæˆæ•°æ®</span></span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> generate_stock_data(n_samples<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>    <span class="co"># å½’ä¸€åŒ–</span></span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>    data_normalized <span class="op">=</span> scaler.fit_transform(data.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åˆ›å»ºåºåˆ—</span></span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> create_sequences(data_normalized, SEQ_LENGTH)</span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.reshape(<span class="op">-</span><span class="dv">1</span>, SEQ_LENGTH, <span class="dv">1</span>)</span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ†å‰²</span></span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(X))</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>    X_train, X_test <span class="op">=</span> X[:train_size], X[train_size:]</span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>    y_train, y_test <span class="op">=</span> y[:train_size], y[train_size:]</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è½¬æ¢ä¸º Tensor</span></span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> torch.FloatTensor(X_train)</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> torch.FloatTensor(y_train).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>    X_test <span class="op">=</span> torch.FloatTensor(X_test)</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>    y_test <span class="op">=</span> torch.FloatTensor(y_test).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ•°æ®åŠ è½½å™¨</span></span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> torch.utils.data.TensorDataset(X_train, y_train)</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>        train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æ¨¡å‹</span></span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> StockLSTM(</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>        input_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>        hidden_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>        num_layers<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æŸå¤±å’Œä¼˜åŒ–å™¨</span></span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>LEARNING_RATE)</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> optim.lr_scheduler.ReduceLROnPlateau(</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>        optimizer, patience<span class="op">=</span><span class="dv">5</span>, factor<span class="op">=</span><span class="fl">0.5</span>, verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒ</span></span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a>    train_losses <span class="op">=</span> []</span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCHS):</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_batch.to(device)</span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device)</span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>            <span class="co"># å‰å‘ä¼ æ’­</span></span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(X_batch)</span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, y_batch)</span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a>            <span class="co"># åå‘ä¼ æ’­</span></span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a>            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb31-156"><a href="#cb31-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-157"><a href="#cb31-157" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a>        train_losses.append(avg_loss)</span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a>        <span class="co"># éªŒè¯</span></span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a>            X_test_device <span class="op">=</span> X_test.to(device)</span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a>            test_pred <span class="op">=</span> model(X_test_device)</span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">=</span> criterion(test_pred, y_test.to(device))</span>
<span id="cb31-168"><a href="#cb31-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-169"><a href="#cb31-169" aria-hidden="true" tabindex="-1"></a>        scheduler.step(test_loss)</span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Epoch [</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>EPOCHS<span class="sc">}</span><span class="ss">], '</span></span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f'Train Loss: </span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">, Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.6f}</span><span class="ss">'</span>)</span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ==================== å¯è§†åŒ–é¢„æµ‹ç»“æœ ====================</span></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-177"><a href="#cb31-177" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb31-178"><a href="#cb31-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-179"><a href="#cb31-179" aria-hidden="true" tabindex="-1"></a>        train_pred <span class="op">=</span> model(X_train.to(device)).cpu().numpy()</span>
<span id="cb31-180"><a href="#cb31-180" aria-hidden="true" tabindex="-1"></a>        test_pred <span class="op">=</span> model(X_test.to(device)).cpu().numpy()</span>
<span id="cb31-181"><a href="#cb31-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-182"><a href="#cb31-182" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åå½’ä¸€åŒ–</span></span>
<span id="cb31-183"><a href="#cb31-183" aria-hidden="true" tabindex="-1"></a>    train_pred <span class="op">=</span> scaler.inverse_transform(train_pred)</span>
<span id="cb31-184"><a href="#cb31-184" aria-hidden="true" tabindex="-1"></a>    test_pred <span class="op">=</span> scaler.inverse_transform(test_pred)</span>
<span id="cb31-185"><a href="#cb31-185" aria-hidden="true" tabindex="-1"></a>    y_train_actual <span class="op">=</span> scaler.inverse_transform(y_train.numpy())</span>
<span id="cb31-186"><a href="#cb31-186" aria-hidden="true" tabindex="-1"></a>    y_test_actual <span class="op">=</span> scaler.inverse_transform(y_test.numpy())</span>
<span id="cb31-187"><a href="#cb31-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-188"><a href="#cb31-188" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ç»˜å›¾</span></span>
<span id="cb31-189"><a href="#cb31-189" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb31-190"><a href="#cb31-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-191"><a href="#cb31-191" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®­ç»ƒé›†</span></span>
<span id="cb31-192"><a href="#cb31-192" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb31-193"><a href="#cb31-193" aria-hidden="true" tabindex="-1"></a>    plt.plot(y_train_actual, label<span class="op">=</span><span class="st">'çœŸå®å€¼'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb31-194"><a href="#cb31-194" aria-hidden="true" tabindex="-1"></a>    plt.plot(train_pred, label<span class="op">=</span><span class="st">'é¢„æµ‹å€¼'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb31-195"><a href="#cb31-195" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'è®­ç»ƒé›†é¢„æµ‹'</span>)</span>
<span id="cb31-196"><a href="#cb31-196" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'æ—¶é—´æ­¥'</span>)</span>
<span id="cb31-197"><a href="#cb31-197" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ä»·æ ¼'</span>)</span>
<span id="cb31-198"><a href="#cb31-198" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb31-199"><a href="#cb31-199" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-200"><a href="#cb31-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-201"><a href="#cb31-201" aria-hidden="true" tabindex="-1"></a>    <span class="co"># æµ‹è¯•é›†</span></span>
<span id="cb31-202"><a href="#cb31-202" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb31-203"><a href="#cb31-203" aria-hidden="true" tabindex="-1"></a>    plt.plot(y_test_actual, label<span class="op">=</span><span class="st">'çœŸå®å€¼'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb31-204"><a href="#cb31-204" aria-hidden="true" tabindex="-1"></a>    plt.plot(test_pred, label<span class="op">=</span><span class="st">'é¢„æµ‹å€¼'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb31-205"><a href="#cb31-205" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'æµ‹è¯•é›†é¢„æµ‹'</span>)</span>
<span id="cb31-206"><a href="#cb31-206" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'æ—¶é—´æ­¥'</span>)</span>
<span id="cb31-207"><a href="#cb31-207" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ä»·æ ¼'</span>)</span>
<span id="cb31-208"><a href="#cb31-208" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb31-209"><a href="#cb31-209" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-210"><a href="#cb31-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-211"><a href="#cb31-211" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb31-212"><a href="#cb31-212" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-213"><a href="#cb31-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-214"><a href="#cb31-214" aria-hidden="true" tabindex="-1"></a>    <span class="co"># è®¡ç®—æŒ‡æ ‡</span></span>
<span id="cb31-215"><a href="#cb31-215" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb31-216"><a href="#cb31-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-217"><a href="#cb31-217" aria-hidden="true" tabindex="-1"></a>    test_mse <span class="op">=</span> mean_squared_error(y_test_actual, test_pred)</span>
<span id="cb31-218"><a href="#cb31-218" aria-hidden="true" tabindex="-1"></a>    test_mae <span class="op">=</span> mean_absolute_error(y_test_actual, test_pred)</span>
<span id="cb31-219"><a href="#cb31-219" aria-hidden="true" tabindex="-1"></a>    test_r2 <span class="op">=</span> r2_score(y_test_actual, test_pred)</span>
<span id="cb31-220"><a href="#cb31-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-221"><a href="#cb31-221" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">æµ‹è¯•é›†æŒ‡æ ‡ï¼š"</span>)</span>
<span id="cb31-222"><a href="#cb31-222" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>test_mse<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-223"><a href="#cb31-223" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"MAE: </span><span class="sc">{</span>test_mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-224"><a href="#cb31-224" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"RÂ²: </span><span class="sc">{</span>test_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-225"><a href="#cb31-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-226"><a href="#cb31-226" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, scaler</span>
<span id="cb31-227"><a href="#cb31-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-228"><a href="#cb31-228" aria-hidden="true" tabindex="-1"></a><span class="co"># è¿è¡Œ</span></span>
<span id="cb31-229"><a href="#cb31-229" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb31-230"><a href="#cb31-230" aria-hidden="true" tabindex="-1"></a>    model, scaler <span class="op">=</span> train_stock_predictor()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="å®æˆ˜-3åºåˆ—åˆ°åºåˆ—-seq2seq" class="level2">
<h2 class="anchored" data-anchor-id="å®æˆ˜-3åºåˆ—åˆ°åºåˆ—-seq2seq">7.9 å®æˆ˜ 3ï¼šåºåˆ—åˆ°åºåˆ— (Seq2Seq)</h2>
<section id="ä»»åŠ¡æœºå™¨ç¿»è¯‘" class="level3">
<h3 class="anchored" data-anchor-id="ä»»åŠ¡æœºå™¨ç¿»è¯‘">ğŸ“‹ ä»»åŠ¡ï¼šæœºå™¨ç¿»è¯‘</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Seq2SeqLSTM(nn.Module):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_vocab_size, output_vocab_size,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                 embedding_size, hidden_size, num_layers<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Seq2SeqLSTM, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encoder</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder_embedding <span class="op">=</span> nn.Embedding(input_vocab_size, embedding_size)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.LSTM(</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>            embedding_size, hidden_size, num_layers,</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Decoder</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decoder_embedding <span class="op">=</span> nn.Embedding(output_vocab_size, embedding_size)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.decoder <span class="op">=</span> nn.LSTM(</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>            embedding_size, hidden_size, num_layers,</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>            batch_first<span class="op">=</span><span class="va">True</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è¾“å‡ºå±‚</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(hidden_size, output_vocab_size)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, src, tgt, teacher_forcing_ratio<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="co">        å‚æ•°ï¼š</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="co">            src: (batch, src_seq_len) æºè¯­è¨€</span></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a><span class="co">            tgt: (batch, tgt_seq_len) ç›®æ ‡è¯­è¨€</span></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="co">            teacher_forcing_ratio: ä½¿ç”¨çœŸå®ç›®æ ‡çš„æ¦‚ç‡</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> src.size(<span class="dv">0</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        tgt_len <span class="op">=</span> tgt.size(<span class="dv">1</span>)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>        tgt_vocab_size <span class="op">=</span> <span class="va">self</span>.fc.out_features</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç¼–ç å™¨</span></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>        embedded_src <span class="op">=</span> <span class="va">self</span>.encoder_embedding(src)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>        encoder_outputs, (hidden, cell) <span class="op">=</span> <span class="va">self</span>.encoder(embedded_src)</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># è§£ç å™¨åˆå§‹è¾“å…¥ï¼ˆ&lt;SOS&gt; tokenï¼‰</span></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>        decoder_input <span class="op">=</span> tgt[:, <span class="dv">0</span>].unsqueeze(<span class="dv">1</span>)</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å­˜å‚¨è¾“å‡º</span></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> torch.zeros(batch_size, tgt_len, tgt_vocab_size)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é€æ­¥è§£ç </span></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, tgt_len):</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># è§£ç ä¸€æ­¥</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>            embedded_tgt <span class="op">=</span> <span class="va">self</span>.decoder_embedding(decoder_input)</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>            decoder_output, (hidden, cell) <span class="op">=</span> <span class="va">self</span>.decoder(</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>                embedded_tgt, (hidden, cell)</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># é¢„æµ‹</span></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> <span class="va">self</span>.fc(decoder_output.squeeze(<span class="dv">1</span>))</span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>            outputs[:, t, :] <span class="op">=</span> output</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Teacher forcing</span></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>            use_teacher_forcing <span class="op">=</span> np.random.random() <span class="op">&lt;</span> teacher_forcing_ratio</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>            top1 <span class="op">=</span> output.argmax(<span class="dv">1</span>)</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>            decoder_input <span class="op">=</span> tgt[:, t].unsqueeze(<span class="dv">1</span>) <span class="cf">if</span> use_teacher_forcing <span class="cf">else</span> top1.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> outputs</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a><span class="co"># ä½¿ç”¨</span></span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Seq2SeqLSTM(</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>    input_vocab_size<span class="op">=</span><span class="dv">5000</span>,</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>    output_vocab_size<span class="op">=</span><span class="dv">5000</span>,</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>    embedding_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>    hidden_size<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>    num_layers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="æœ¬ç« ä½œä¸š" class="level2">
<h2 class="anchored" data-anchor-id="æœ¬ç« ä½œä¸š">ğŸ“ æœ¬ç« ä½œä¸š</h2>
<section id="ä½œä¸š-1rnn-æ¢¯åº¦åˆ†æ" class="level3">
<h3 class="anchored" data-anchor-id="ä½œä¸š-1rnn-æ¢¯åº¦åˆ†æ">ä½œä¸š 1ï¼šRNN æ¢¯åº¦åˆ†æ</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">:</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. å®ç° vanilla RNN</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. åœ¨é•¿åºåˆ—ä¸Šè®­ç»ƒ</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. å¯è§†åŒ–æ¢¯åº¦æµ</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. è§‚å¯Ÿæ¢¯åº¦æ¶ˆå¤±ç°è±¡</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. å¯¹æ¯” LSTM çš„æ¢¯åº¦æµ</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="ä½œä¸š-2æƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®" class="level3">
<h3 class="anchored" data-anchor-id="ä½œä¸š-2æƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®">ä½œä¸š 2ï¼šæƒ…æ„Ÿåˆ†æå®Œæ•´é¡¹ç›®</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆIMDB æˆ–ä¸­æ–‡è¯„è®ºï¼‰</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># è¦æ±‚ï¼š</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. æ•°æ®é¢„å¤„ç†å’Œ EDA</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. å®ç° LSTM å’Œ GRU æ¨¡å‹</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. å¯¹æ¯”åŒå‘å’Œå•å‘</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. åŠ å…¥æ³¨æ„åŠ›æœºåˆ¶</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. è¶…å‚æ•°è°ƒä¼˜</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. ç¼–å†™å®Œæ•´æŠ¥å‘Š</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="ä½œä¸š-3æ–‡æœ¬ç”Ÿæˆ" class="level3">
<h3 class="anchored" data-anchor-id="ä½œä¸š-3æ–‡æœ¬ç”Ÿæˆ">ä½œä¸š 3ï¼šæ–‡æœ¬ç”Ÿæˆ</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># å­—ç¬¦çº§è¯­è¨€æ¨¡å‹</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ä½¿ç”¨èå£«æ¯”äºšæ–‡æœ¬è®­ç»ƒ</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. å®ç° LSTM ç”Ÿæˆæ¨¡å‹</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. å°è¯•ä¸åŒçš„é‡‡æ ·ç­–ç•¥ï¼ˆè´ªå¿ƒã€top-kã€nucleusï¼‰</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. ç”Ÿæˆæ–°æ–‡æœ¬å¹¶è¯„ä¼°è´¨é‡</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
</section>
<section id="æœ¬ç« å…³é”®æ¦‚å¿µ" class="level2">
<h2 class="anchored" data-anchor-id="æœ¬ç« å…³é”®æ¦‚å¿µ">ğŸ”‘ æœ¬ç« å…³é”®æ¦‚å¿µ</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>æ¦‚å¿µ</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>åºåˆ—æ•°æ®</td>
<td>å‰åæœ‰ä¾èµ–å…³ç³»çš„æ•°æ®</td>
</tr>
<tr class="even">
<td>RNN</td>
<td>å¾ªç¯ç¥ç»ç½‘ç»œï¼Œå¤„ç†åºåˆ—</td>
</tr>
<tr class="odd">
<td>éšè—çŠ¶æ€</td>
<td>åºåˆ—ä¿¡æ¯çš„è½½ä½“</td>
</tr>
<tr class="even">
<td>BPTT</td>
<td>åå‘ä¼ æ’­ç©¿è¶Šæ—¶é—´</td>
</tr>
<tr class="odd">
<td>æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸</td>
<td>RNN çš„æ ¸å¿ƒé—®é¢˜</td>
</tr>
<tr class="even">
<td>LSTM</td>
<td>é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ</td>
</tr>
<tr class="odd">
<td>é—¨æ§æœºåˆ¶</td>
<td>æ§åˆ¶ä¿¡æ¯æµ</td>
</tr>
<tr class="even">
<td>ç»†èƒçŠ¶æ€</td>
<td>LSTM çš„é•¿æœŸè®°å¿†</td>
</tr>
<tr class="odd">
<td>GRU</td>
<td>ç®€åŒ–çš„ LSTM</td>
</tr>
<tr class="even">
<td>åŒå‘ RNN</td>
<td>åŒæ—¶çœ‹å‰åæ–‡</td>
</tr>
</tbody>
</table>
<hr>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Chapter6.html" class="pagination-link" aria-label="ç¬¬å…­ç« ï¼šå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">ç¬¬å…­ç« ï¼šå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Chapter8.html" class="pagination-link" aria-label="ç¬¬å…«ç« ï¼šAttention ä¸ Transformer">
        <span class="nav-page-text"><span class="chapter-title">ç¬¬å…«ç« ï¼šAttention ä¸ Transformer</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>